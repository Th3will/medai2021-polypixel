{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-09-27T17:05:39.089052Z",
     "iopub.status.busy": "2021-09-27T17:05:39.088769Z",
     "iopub.status.idle": "2021-09-27T17:05:42.72167Z",
     "shell.execute_reply": "2021-09-27T17:05:42.720849Z",
     "shell.execute_reply.started": "2021-09-27T17:05:39.089002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import time\n",
    "from contextlib import contextmanager # timer\n",
    "from functools import partial\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.model_selection import KFold\n",
    "import random\n",
    "from skimage.transform import rescale, resize\n",
    "from scipy.ndimage import rotate\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import SimpleITK as sitk\n",
    "print(os.listdir(\"../input/\"))\n",
    "from skimage import data, img_as_float\n",
    "from skimage import exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:05:42.723904Z",
     "iopub.status.busy": "2021-09-27T17:05:42.723446Z",
     "iopub.status.idle": "2021-09-27T17:05:42.730756Z",
     "shell.execute_reply": "2021-09-27T17:05:42.729959Z",
     "shell.execute_reply.started": "2021-09-27T17:05:42.723854Z"
    }
   },
   "outputs": [],
   "source": [
    "def batch_generator(batch_size, gen_x): \n",
    "    batch_features = np.zeros((batch_size,256,256,3))\n",
    "    batch_labels = np.zeros((batch_size,256,256,3)) \n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            batch_features[i] , batch_labels[i] = next(gen_x)\n",
    "        yield batch_features, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:05:42.732944Z",
     "iopub.status.busy": "2021-09-27T17:05:42.73244Z",
     "iopub.status.idle": "2021-09-27T17:05:42.761414Z",
     "shell.execute_reply": "2021-09-27T17:05:42.760393Z",
     "shell.execute_reply.started": "2021-09-27T17:05:42.732716Z"
    }
   },
   "outputs": [],
   "source": [
    "def gaussian_noise(img, mean=0, sigma=0.03):\n",
    "    img = img.copy()\n",
    "    noise = np.random.normal(mean, sigma, img.shape)\n",
    "    mask_overflow_upper = img+noise >= 1.0\n",
    "    mask_overflow_lower = img+noise < 0\n",
    "    noise[mask_overflow_upper] = 1.0\n",
    "    noise[mask_overflow_lower] = 0\n",
    "    img += noise\n",
    "    return img\n",
    "\n",
    "#https://towardsdatascience.com/complete-image-augmentation-in-opencv-31a6b02694f5\n",
    "def brightness(img, low, high):\n",
    "    value = random.uniform(low, high)\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    hsv = np.array(hsv, dtype = np.float64)\n",
    "    hsv[:,:,1] = hsv[:,:,1]*value\n",
    "    hsv[:,:,1][hsv[:,:,1]>255]  = 255\n",
    "    hsv[:,:,2] = hsv[:,:,2]*value \n",
    "    hsv[:,:,2][hsv[:,:,2]>255]  = 255\n",
    "    hsv = np.array(hsv, dtype = np.uint8)\n",
    "    img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    return img\n",
    "\n",
    "#https://towardsdatascience.com/complete-image-augmentation-in-opencv-31a6b02694f5\n",
    "def fill(img, h, w):\n",
    "    img = img.astype('float32')\n",
    "    img = cv2.resize(img, (h, w), cv2.INTER_CUBIC)\n",
    "    return img\n",
    "def zoom(img, mask, value):\n",
    "    if value > 1 or value < 0:\n",
    "        print('Value for zoom should be less than 1 and greater than 0')\n",
    "        return img, mask\n",
    "    value = random.uniform(value, 1)\n",
    "    h, w = img.shape[:2]\n",
    "    h_taken = int(value*h)\n",
    "    w_taken = int(value*w)\n",
    "    h_start = random.randint(0, h-h_taken)\n",
    "    w_start = random.randint(0, w-w_taken)\n",
    "    img = img[h_start:h_start+h_taken, w_start:w_start+w_taken, :]\n",
    "    img = fill(img, h, w)\n",
    "    mask = mask[h_start:h_start+h_taken, w_start:w_start+w_taken, :]\n",
    "    mask = fill(mask, h, w)\n",
    "    return img, mask\n",
    "\n",
    "# https://towardsdatascience.com/complete-image-augmentation-in-opencv-31a6b02694f5\n",
    "def vertical_shift(img, mask, ratio=0.0):\n",
    "    if ratio > 1 or ratio < 0:\n",
    "        print('Value should be less than 1 and greater than 0')\n",
    "        return img, mask\n",
    "    ratio = random.uniform(-ratio, ratio)\n",
    "    h, w = img.shape[:2]\n",
    "    to_shift = h*ratio\n",
    "    if ratio > 0:\n",
    "        img = img[:, :int(w-to_shift), :]\n",
    "        mask = mask[:, :int(w-to_shift), :]\n",
    "    if ratio < 0:\n",
    "        img = img[:, int(-1*to_shift):, :]\n",
    "        mask = mask[:, int(-1*to_shift):, :]\n",
    "    img = fill(img, h, w)\n",
    "    mask = fill(mask, h, w)\n",
    "    return img, mask\n",
    "\n",
    "# https://towardsdatascience.com/complete-image-augmentation-in-opencv-31a6b02694f5 \n",
    "def horizontal_shift(img, mask, ratio=0.0):\n",
    "    if ratio > 1 or ratio < 0:\n",
    "        print('Value should be less than 1 and greater than 0')\n",
    "        return img, mask\n",
    "    ratio = random.uniform(-ratio, ratio)\n",
    "    h, w = img.shape[:2]\n",
    "    to_shift = w*ratio\n",
    "    if ratio > 0:\n",
    "        img = img[:, :int(w-to_shift), :]\n",
    "        mask = mask[:, :int(w-to_shift), :]\n",
    "    if ratio < 0:\n",
    "        img = img[:, int(-1*to_shift):, :]\n",
    "        mask = mask[:, int(-1*to_shift):, :]\n",
    "    img = fill(img, h, w)\n",
    "    mask = fill(mask, h, w)\n",
    "    return img,mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:05:42.764939Z",
     "iopub.status.busy": "2021-09-27T17:05:42.76465Z",
     "iopub.status.idle": "2021-09-27T17:05:42.783544Z",
     "shell.execute_reply": "2021-09-27T17:05:42.78274Z",
     "shell.execute_reply.started": "2021-09-27T17:05:42.764846Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_data(filelist, img_path, mask_path, gen_type = \"train\"):\n",
    "    while True:\n",
    "        for i in filelist:\n",
    "            X_train = cv2.imread(img_path + i, cv2.IMREAD_COLOR )\n",
    "            X_train = cv2.resize(X_train, (256,256), interpolation= cv2.INTER_LINEAR )\n",
    "            y_mask = cv2.imread(mask_path + i, cv2.IMREAD_COLOR)\n",
    "            y_mask = cv2.resize(y_mask, (256,256), interpolation= cv2.IMREAD_GRAYSCALE)\n",
    "            _,y_mask = cv2.threshold(y_mask, 127, 255, cv2.THRESH_BINARY)\n",
    "            y_train = (y_mask/255).astype(int)\n",
    "            if gen_type == \"train\":\n",
    "                # returns a random integer used to select augmentataion techniques for a given sample\n",
    "                augment_num = np.random.randint(0,9)\n",
    "                if augment_num == 0:\n",
    "                    # do nothing\n",
    "                    X_train = X_train\n",
    "                elif augment_num == 1:\n",
    "                    #random noise\n",
    "                    X_train = X_train + np.random.rand(X_train.shape[0], X_train.shape[1], X_train.shape[2])*np.random.randint(-100,100)\n",
    "                elif augment_num == 2:\n",
    "                    X_train = cv2.GaussianBlur(X_train,(random.randrange(1,50,2),random.randrange(1,50,2)), 0)\n",
    "                elif augment_num == 3:\n",
    "                    rot = np.random.randint(-45,45)\n",
    "                    X_train = rotate(X_train,rot, reshape=False)\n",
    "                    y_train = rotate(y_train,rot, reshape=False)\n",
    "                elif augment_num == 4:\n",
    "                    X_train = brightness(X_train,0.5,3)\n",
    "                elif augment_num == 5:\n",
    "                    X_train = np.fliplr(X_train)\n",
    "                    y_train = np.fliplr(y_train)\n",
    "                elif augment_num == 6:\n",
    "                    X_train = np.flipud(X_train)\n",
    "                    y_train = np.flipud(y_train)\n",
    "                elif augment_num == 7:\n",
    "                    hshift = round(random.uniform(0.1, 0.3),3)\n",
    "                    X_train, y_train = horizontal_shift(X_train, y_train, hshift)\n",
    "                elif augment_num == 8:\n",
    "                    vshift = round(random.uniform(0.1, 0.3),3)\n",
    "                    X_train, y_train = vertical_shift(X_train, y_train, vshift)\n",
    "                elif augment_num == 9:\n",
    "                    zoom_rate = round(random.uniform(0.8, 0.95),3)\n",
    "                    X_train, y_train = zoom(X_train, y_train, zoom_rate)\n",
    "                elif augment_num == 10:\n",
    "                    #contrast\n",
    "                    X_train = exposure.equalize_adapthist(X_train.astype(int), clip_limit=0.03)  \n",
    "                elif augment_num == 11:\n",
    "                    #contrast\n",
    "                    X_train = exposure.equalize_hist(X_train.astype(int))  \n",
    "            yield X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:05:42.787949Z",
     "iopub.status.busy": "2021-09-27T17:05:42.787415Z",
     "iopub.status.idle": "2021-09-27T17:05:42.797918Z",
     "shell.execute_reply": "2021-09-27T17:05:42.79679Z",
     "shell.execute_reply.started": "2021-09-27T17:05:42.787898Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_data_pred(filelist, img_path, mask_path, gen_type = \"train\"):\n",
    "    while True:\n",
    "        for i in filelist:\n",
    "            original_img = cv2.imread(img_path + i, cv2.IMREAD_COLOR )\n",
    "            X_train = cv2.resize(original_img, (256,256), interpolation= cv2.INTER_LINEAR )\n",
    "            if gen_type == \"train\":\n",
    "                X_train = X_train * np.random.choice([1,1,1,np.random.rand(256, 256,3)])\n",
    "            original_mask = cv2.imread(mask_path + i, cv2.IMREAD_COLOR)\n",
    "            y_mask = cv2.resize(original_mask, (256,256), interpolation= cv2.IMREAD_GRAYSCALE)\n",
    "            _,y_mask = cv2.threshold(y_mask, 127, 255, cv2.THRESH_BINARY)\n",
    "            y_mask = (y_mask/255).astype(int)\n",
    "            yield original_img, original_mask, X_train, y_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:05:42.801191Z",
     "iopub.status.busy": "2021-09-27T17:05:42.800673Z",
     "iopub.status.idle": "2021-09-27T17:05:42.808672Z",
     "shell.execute_reply": "2021-09-27T17:05:42.807882Z",
     "shell.execute_reply.started": "2021-09-27T17:05:42.800932Z"
    }
   },
   "outputs": [],
   "source": [
    "def dice_score(mask_gt, mask_pred):\n",
    "    \"\"\"Computes soerensen-dice coefficient.\n",
    "\n",
    "    compute the soerensen-dice coefficient between the ground truth mask `mask_gt`\n",
    "    and the predicted mask `mask_pred`.\n",
    "\n",
    "    Args:\n",
    "    mask_gt: 3-dim Numpy array of type bool. The ground truth mask.\n",
    "    mask_pred: 3-dim Numpy array of type bool. The predicted mask.\n",
    "\n",
    "    Returns:\n",
    "    the dice coeffcient as float. If both masks are empty, the result is NaN.\n",
    "    \"\"\"\n",
    "    volume_sum = mask_gt.sum() + mask_pred.sum()\n",
    "    if volume_sum == 0:\n",
    "        return np.NaN\n",
    "    volume_intersect = (mask_gt & mask_pred).sum()\n",
    "    return 2*volume_intersect / volume_sum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:05:42.810554Z",
     "iopub.status.busy": "2021-09-27T17:05:42.810022Z",
     "iopub.status.idle": "2021-09-27T17:05:44.345213Z",
     "shell.execute_reply": "2021-09-27T17:05:44.344487Z",
     "shell.execute_reply.started": "2021-09-27T17:05:42.810503Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 10:29:01.848325: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-18 10:29:01.880074: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-18 10:29:02.388256: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "# From: https://gist.github.com/wassname/7793e2058c5c9dacb5212c0ac0b18a8a\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    \"\"\"\n",
    "    Dice = (2*|X & Y|)/ (|X|+ |Y|)\n",
    "         =  2*sum(|A*B|)/(sum(A^2)+sum(B^2))\n",
    "    ref: https://arxiv.org/pdf/1606.04797v1.pdf\n",
    "    \"\"\"\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    return (2. * intersection + smooth) / (K.sum(K.square(y_true),-1) + K.sum(K.square(y_pred),-1) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:05:44.346848Z",
     "iopub.status.busy": "2021-09-27T17:05:44.346585Z",
     "iopub.status.idle": "2021-09-27T17:05:44.360838Z",
     "shell.execute_reply": "2021-09-27T17:05:44.359768Z",
     "shell.execute_reply.started": "2021-09-27T17:05:44.346806Z"
    }
   },
   "outputs": [],
   "source": [
    "def jacard_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
    "\n",
    "\n",
    "def jacard_coef_loss(y_true, y_pred):\n",
    "    return 1-jacard_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:05:44.363193Z",
     "iopub.status.busy": "2021-09-27T17:05:44.362847Z",
     "iopub.status.idle": "2021-09-27T17:05:44.413335Z",
     "shell.execute_reply": "2021-09-27T17:05:44.412527Z",
     "shell.execute_reply.started": "2021-09-27T17:05:44.363117Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def get_model(img_size, num_classes):\n",
    "\n",
    "    inputs = tf.keras.Input(shape=img_size + (3,))\n",
    "    #inputs = tf.keras.Input(shape=(256,256,3))\n",
    "    #inputs = tf.keras.Input(shape=img_size + (1,))\n",
    "    ### [First half of the network: downsampling inputs] ###\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
    "    for filters in [64, 128, 256]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    ### [Second half of the network: upsampling inputs] ###\n",
    "\n",
    "    for filters in [256, 128, 64, 32]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.UpSampling2D(2)(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.UpSampling2D(2)(previous_block_activation)\n",
    "        residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    # Add a per-pixel classification layer\n",
    "    outputs = layers.Conv2D(num_classes, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "\n",
    "    # Define the model\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=jacard_coef_loss, metrics = [jacard_coef, dice_coef])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Free up RAM in case the model definition cells were run multiple times\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Build model\n",
    "#model = get_model(img_size, num_classes)\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:05:44.415042Z",
     "iopub.status.busy": "2021-09-27T17:05:44.414655Z",
     "iopub.status.idle": "2021-09-27T17:05:44.420506Z",
     "shell.execute_reply": "2021-09-27T17:05:44.419485Z",
     "shell.execute_reply.started": "2021-09-27T17:05:44.414998Z"
    }
   },
   "outputs": [],
   "source": [
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.1, patience=3, verbose=1, mode='min',\n",
    "    min_delta=0.0001, cooldown=5, min_lr=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:05:44.422676Z",
     "iopub.status.busy": "2021-09-27T17:05:44.422136Z",
     "iopub.status.idle": "2021-09-27T17:05:52.114449Z",
     "shell.execute_reply": "2021-09-27T17:05:52.113677Z",
     "shell.execute_reply.started": "2021-09-27T17:05:44.422396Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: segmentation-models==1.0.1 in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (1.0.1)\n",
      "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from segmentation-models==1.0.1) (1.0.8)\n",
      "Requirement already satisfied: image-classifiers==1.0.0 in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from segmentation-models==1.0.1) (1.0.0)\n",
      "Requirement already satisfied: efficientnet==1.0.0 in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from segmentation-models==1.0.1) (1.0.0)\n",
      "Requirement already satisfied: scikit-image in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from efficientnet==1.0.0->segmentation-models==1.0.1) (0.21.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models==1.0.1) (1.24.3)\n",
      "Requirement already satisfied: h5py in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models==1.0.1) (3.9.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (2023.7.10)\n",
      "Requirement already satisfied: scipy>=1.8 in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (1.11.1)\n",
      "Requirement already satisfied: packaging>=21 in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (23.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (1.4.1)\n",
      "Requirement already satisfied: pillow>=9.0.1 in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (9.3.0)\n",
      "Requirement already satisfied: lazy_loader>=0.2 in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (0.3)\n",
      "Requirement already satisfied: imageio>=2.27 in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (2.31.1)\n",
      "Requirement already satisfied: networkx>=2.8 in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install segmentation-models==1.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SM_FRAMEWORK=tf.keras\n"
     ]
    }
   ],
   "source": [
    "%env SM_FRAMEWORK=tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:05:52.116286Z",
     "iopub.status.busy": "2021-09-27T17:05:52.116006Z",
     "iopub.status.idle": "2021-09-27T17:05:52.140965Z",
     "shell.execute_reply": "2021-09-27T17:05:52.140205Z",
     "shell.execute_reply.started": "2021-09-27T17:05:52.116239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `tf.keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import segmentation_models as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:05:52.142554Z",
     "iopub.status.busy": "2021-09-27T17:05:52.142246Z",
     "iopub.status.idle": "2021-09-27T17:06:12.650457Z",
     "shell.execute_reply": "2021-09-27T17:06:12.649701Z",
     "shell.execute_reply.started": "2021-09-27T17:05:52.142507Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting neptune-client\n",
      "  Downloading neptune_client-1.3.2-py3-none-any.whl (455 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m455.3/455.3 KB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from neptune-client) (5.9.5)\n",
      "Collecting future>=0.17.1\n",
      "  Downloading future-0.18.3.tar.gz (840 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.9/840.9 KB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: boto3>=1.16.0 in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from neptune-client) (1.16.63)\n",
      "Requirement already satisfied: Pillow>=1.1.6 in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from neptune-client) (9.3.0)\n",
      "Requirement already satisfied: packaging in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from neptune-client) (23.1)\n",
      "Collecting swagger-spec-validator>=2.7.4\n",
      "  Downloading swagger_spec_validator-3.0.3-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: requests>=2.20.0 in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from neptune-client) (2.28.0)\n",
      "Requirement already satisfied: click>=7.0 in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from neptune-client) (8.1.3)\n",
      "Requirement already satisfied: oauthlib>=2.1.0 in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from neptune-client) (3.2.2)\n",
      "Requirement already satisfied: websocket-client!=1.0.0,>=0.35.0 in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from neptune-client) (1.6.1)\n",
      "Requirement already satisfied: pandas in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from neptune-client) (1.5.3)\n",
      "Requirement already satisfied: urllib3 in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from neptune-client) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=1.0.0 in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from neptune-client) (1.3.1)\n",
      "Collecting bravado<12.0.0,>=11.0.0\n",
      "  Downloading bravado-11.0.3-py2.py3-none-any.whl (38 kB)\n",
      "Collecting PyJWT\n",
      "  Downloading PyJWT-2.7.0-py3-none-any.whl (22 kB)\n",
      "Collecting GitPython>=2.0.8\n",
      "  Downloading GitPython-3.1.32-py3-none-any.whl (188 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.5/188.5 KB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from neptune-client) (1.16.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from boto3>=1.16.0->neptune-client) (0.3.7)\n",
      "Requirement already satisfied: botocore<1.20.0,>=1.19.63 in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from boto3>=1.16.0->neptune-client) (1.19.63)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from boto3>=1.16.0->neptune-client) (0.10.0)\n",
      "Requirement already satisfied: simplejson in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (3.19.1)\n",
      "Requirement already satisfied: pyyaml in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (6.0)\n",
      "Collecting msgpack\n",
      "  Downloading msgpack-1.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (316 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.8/316.8 KB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (4.5.0)\n",
      "Collecting monotonic\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: python-dateutil in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (2.8.2)\n",
      "Collecting bravado-core>=5.16.1\n",
      "  Downloading bravado_core-5.17.1-py2.py3-none-any.whl (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 KB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from requests>=2.20.0->neptune-client) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from requests>=2.20.0->neptune-client) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from requests>=2.20.0->neptune-client) (3.4)\n",
      "Requirement already satisfied: jsonschema in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from swagger-spec-validator>=2.7.4->neptune-client) (4.17.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from pandas->neptune-client) (2022.7.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from pandas->neptune-client) (1.24.3)\n",
      "Collecting jsonref\n",
      "  Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (0.19.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (23.1.0)\n",
      "Requirement already satisfied: isoduration in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (2.4)\n",
      "Requirement already satisfied: uri-template in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (1.3.0)\n",
      "Requirement already satisfied: rfc3339-validator in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (0.1.4)\n",
      "Requirement already satisfied: webcolors>=1.11 in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (1.13)\n",
      "Requirement already satisfied: fqdn in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (1.5.1)\n",
      "Collecting rfc3987\n",
      "  Downloading rfc3987-1.3.8-py2.py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages (from isoduration->jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (1.2.3)\n",
      "Building wheels for collected packages: future\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492035 sha256=10d2d06ee824a2da32732375a392a481a39c80784c3d8844c6e43af761896909\n",
      "  Stored in directory: /home/wni1717/.cache/pip/wheels/5e/a9/47/f118e66afd12240e4662752cc22cefae5d97275623aa8ef57d\n",
      "Successfully built future\n",
      "Installing collected packages: rfc3987, msgpack, monotonic, smmap, PyJWT, jsonref, future, swagger-spec-validator, gitdb, GitPython, bravado-core, bravado, neptune-client\n",
      "Successfully installed GitPython-3.1.32 PyJWT-2.7.0 bravado-11.0.3 bravado-core-5.17.1 future-0.18.3 gitdb-4.0.10 jsonref-1.1.0 monotonic-1.6 msgpack-1.0.5 neptune-client-1.3.2 rfc3987-1.3.8 smmap-5.0.0 swagger-spec-validator-3.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install neptune-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:06:12.654813Z",
     "iopub.status.busy": "2021-09-27T17:06:12.654536Z",
     "iopub.status.idle": "2021-09-27T17:06:12.889422Z",
     "shell.execute_reply": "2021-09-27T17:06:12.888748Z",
     "shell.execute_reply.started": "2021-09-27T17:06:12.654755Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wni1717/dev/OTUMEDAI/venv/lib/python3.10/site-packages/neptune/internal/backends/hosted_client.py:51: NeptuneDeprecationWarning: The 'neptune-client' package has been deprecated and will be removed in the future. Install the 'neptune' package instead. For more, see https://docs.neptune.ai/setup/upgrading/\n",
      "  from neptune.version import version as neptune_client_version\n",
      "/tmp/ipykernel_1164/3044403751.py:1: NeptuneDeprecationWarning: You're importing the Neptune client library via the deprecated `neptune.new` module, which will be removed in a future release. Import directly from `neptune` instead.\n",
      "  import neptune.new as neptune\n"
     ]
    }
   ],
   "source": [
    "import neptune.new as neptune\n",
    "from sklearn.metrics import jaccard_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:06:12.891807Z",
     "iopub.status.busy": "2021-09-27T17:06:12.891284Z",
     "iopub.status.idle": "2021-09-27T17:06:12.904756Z",
     "shell.execute_reply": "2021-09-27T17:06:12.904047Z",
     "shell.execute_reply.started": "2021-09-27T17:06:12.891758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfile_list = np.asarray(os.listdir(\"../input/hyperkvasiraugustversion/Kvasir-SEG/images\"))\\nimage_path = \"../input/hyperkvasiraugustversion/Kvasir-SEG/images/\" \\nmask_path = \"../input/hyperkvasiraugustversion/Kvasir-SEG/masks/\"\\n\\nrun = neptune.init(project=\\'SSCP/HyperKvasir\\',\\n                   api_token=\\'eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIzMGUyN2Q2ZS05MjVkLTRlMzItODYwZS0yODQ3ZWU3ZTdmMmEifQ==\\') # your credentials\\n\\n\\nbatchsize = 10\\ndata_size = len(file_list)\\nnum_epoch = 25\\nsplits = 10\\nkf = KFold(n_splits=splits)\\nvalsize = data_size // splits\\ntrainsize = data_size - valsize\\nmy_model = \"efficientnetb0\"\\ndata_num = np.arange(data_size)\\n\\nimg_size = (256, 256)\\nnum_classes = 3\\n\\nrun[\"Dataset\"] = \"Polyp\"\\nrun[\"Model\"] = my_model\\nrun[\"CV-folds\"] = splits\\nrun[\"Epochs\"] = num_epoch\\nrun[\"Batch size\"] = batchsize\\nrun[\"pretrained\"] = \"Imagenet\"\\n##########################################################################################\\n# Check what augmentation techniques you use and say \"yes\" or \"no\" in the fields bellow  #\\n# You can also add new fields                                                            #\\n##########################################################################################\\nrun[\"noise\"] = \"yes\"\\nrun[\"blurring\"] = \"yes\"\\nrun[\"cropping\"] = \"no\"\\nrun[\"flipping\"] = \"yes\"\\nrun[\"rotation\"] = \"yes\"\\nrun[\"zoom\"] = \"yes\"\\nrun[\"translation\"] = \"no\"\\nrun[\"brightness\"] = \"yes\"\\nrun[\"contrast_hist\"] = \"no\"\\nrun[\"contrast_adaptive\"] = \"no\"\\nrun[\"color augmentation\"] = \"no\"\\nrun[\"saturation\"] =\"no\"\\nrun[\"horizontal shift\"] = \"yes\"\\nrun[\"vertical shift\"] = \"yes\"\\n\\nvalidation_dice_original = np.zeros([valsize,splits])\\nvalidation_dice_resized = np.zeros([valsize,splits])\\n#validation_jaccard_original = np.zeros([valsize,splits])\\n#validation_jaccard_resized = np.zeros([valsize,splits])\\n\\ncv_count = 0\\n\\nfor train_index, val_index in kf.split(data_num):\\n    #model = get_model(img_size, num_classes)\\n    model = sm.Unet(my_model, encoder_weights=\\'imagenet\\', input_shape=( 256,256, 3), classes=3, activation=\\'sigmoid\\')\\n    model.compile(optimizer=\\'Adam\\', loss=jacard_coef_loss, metrics = [jacard_coef, dice_coef])\\n    model.fit(x=batch_generator(batchsize, generate_data(file_list[train_index], image_path, mask_path, gen_type = \"train\")), epochs=num_epoch, \\n                            steps_per_epoch=(trainsize/batchsize), \\n                            validation_steps=(valsize/batchsize),\\n                            validation_data=batch_generator(batchsize, generate_data(file_list[val_index], image_path, mask_path, gen_type = \"val\")), \\n                            validation_freq=1, \\n                            verbose = 1, \\n                            callbacks=[reduce_lr],\\n                            )\\n    val_gen  = generate_data_pred(file_list[val_index], image_path, mask_path, gen_type = \"val\")\\n    for i in range(valsize):\\n        time_start = time.time()\\n        original_img, original_mask, X, y_true = next(val_gen)\\n        original_shape = original_img.shape\\n        y_pred = model.predict(np.expand_dims(X,0))\\n        _,y_pred_thr = cv2.threshold(y_pred[0,:,:,0]*255, 127, 255, cv2.THRESH_BINARY)\\n        y_pred = (y_pred_thr/255).astype(int)\\n        dice_resized = dice_score(y_true[:,:,0],y_pred)\\n        #jaccard_resized = jaccard_score(y_true[:,:,0],y_pred, average=\"macro\")\\n        \\n        y_pred_original = cv2.resize(y_pred.astype(float), (original_shape[1],original_shape[0]), interpolation= cv2.INTER_LINEAR)\\n        dice_original = dice_score(original_mask[:,:,0],y_pred_original.astype(int)*255)\\n        #jaccard_original = jaccard_score(original_mask[:,:,0],y_pred_original.astype(int)*255, average=\"macro\")\\n        \\n        validation_dice_original[i,cv_count] = dice_original\\n        validation_dice_resized[i,cv_count] = dice_resized\\n        #validation_jaccard_original[i,cv_count] = jaccard_original\\n        #validation_jaccard_resized[i,cv_count] = jaccard_resized\\n        \\n        if i < 5:\\n            plt.figure(figsize=(20,10))\\n            plt.subplot(1,2,1)\\n            plt.imshow(original_img, \\'gray\\', interpolation=\\'none\\')\\n            plt.imshow(original_mask/255.0, \\'jet\\', interpolation=\\'none\\', alpha=0.4)\\n            plt.subplot(1,2,2)\\n            plt.imshow(original_img, \\'gray\\', interpolation=\\'none\\')\\n            plt.imshow(y_pred_original, \\'jet\\', interpolation=\\'none\\', alpha=0.4)\\n            plt.show()\\n        \\n    dice_resized_mean = validation_dice_resized[:,cv_count].mean()\\n    dice_original_mean = validation_dice_original[:,cv_count].mean()\\n    #jaccard_resized_mean = validation_jaccard_resized[:,cv_count].mean()\\n    #jaccard_original_mean = validation_jaccard_original[:,cv_count].mean()\\n        \\n    print(\"--------------------------------------\")\\n    print(\"Mean validation DICE (on resized data):\", dice_resized_mean) \\n    print(\"Mean validation DICE (on original data):\", dice_original_mean)\\n    print(\"--------------------------------------\")\\n    #print(\"Mean validation Jaccard (on resized data):\", jaccard_resized_mean) \\n    #print(\"Mean validation Jaccard (on original data):\", jaccard_original_mean)\\n    #print(\"--------------------------------------\")\\n    run[\"Dice Resized\"].log(dice_resized_mean)\\n    run[\"Dice Original\"].log(dice_original_mean)\\n    #run[\"Jaccard Resized\"].log(jaccard_resized_mean)\\n    #run[\"Jaccard Original\"].log(jaccard_original_mean)\\n    runtime = time.time() - time_start \\n    print(\\'Runtime: {} sec\\'.format(runtime))\\n    run[\"Runtime\"] = runtime\\n    cv_count +=1\\nrun.stop()\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "file_list = np.asarray(os.listdir(\"../input/hyperkvasiraugustversion/Kvasir-SEG/images\"))\n",
    "image_path = \"../input/hyperkvasiraugustversion/Kvasir-SEG/images/\" \n",
    "mask_path = \"../input/hyperkvasiraugustversion/Kvasir-SEG/masks/\"\n",
    "\n",
    "run = neptune.init(project='SSCP/HyperKvasir',\n",
    "                   api_token='eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIzMGUyN2Q2ZS05MjVkLTRlMzItODYwZS0yODQ3ZWU3ZTdmMmEifQ==') # your credentials\n",
    "\n",
    "\n",
    "batchsize = 10\n",
    "data_size = len(file_list)\n",
    "num_epoch = 25\n",
    "splits = 10\n",
    "kf = KFold(n_splits=splits)\n",
    "valsize = data_size // splits\n",
    "trainsize = data_size - valsize\n",
    "my_model = \"efficientnetb0\"\n",
    "data_num = np.arange(data_size)\n",
    "\n",
    "img_size = (256, 256)\n",
    "num_classes = 3\n",
    "\n",
    "run[\"Dataset\"] = \"Polyp\"\n",
    "run[\"Model\"] = my_model\n",
    "run[\"CV-folds\"] = splits\n",
    "run[\"Epochs\"] = num_epoch\n",
    "run[\"Batch size\"] = batchsize\n",
    "run[\"pretrained\"] = \"Imagenet\"\n",
    "##########################################################################################\n",
    "# Check what augmentation techniques you use and say \"yes\" or \"no\" in the fields bellow  #\n",
    "# You can also add new fields                                                            #\n",
    "##########################################################################################\n",
    "run[\"noise\"] = \"yes\"\n",
    "run[\"blurring\"] = \"yes\"\n",
    "run[\"cropping\"] = \"no\"\n",
    "run[\"flipping\"] = \"yes\"\n",
    "run[\"rotation\"] = \"yes\"\n",
    "run[\"zoom\"] = \"yes\"\n",
    "run[\"translation\"] = \"no\"\n",
    "run[\"brightness\"] = \"yes\"\n",
    "run[\"contrast_hist\"] = \"no\"\n",
    "run[\"contrast_adaptive\"] = \"no\"\n",
    "run[\"color augmentation\"] = \"no\"\n",
    "run[\"saturation\"] =\"no\"\n",
    "run[\"horizontal shift\"] = \"yes\"\n",
    "run[\"vertical shift\"] = \"yes\"\n",
    "\n",
    "validation_dice_original = np.zeros([valsize,splits])\n",
    "validation_dice_resized = np.zeros([valsize,splits])\n",
    "#validation_jaccard_original = np.zeros([valsize,splits])\n",
    "#validation_jaccard_resized = np.zeros([valsize,splits])\n",
    "\n",
    "cv_count = 0\n",
    "\n",
    "for train_index, val_index in kf.split(data_num):\n",
    "    #model = get_model(img_size, num_classes)\n",
    "    model = sm.Unet(my_model, encoder_weights='imagenet', input_shape=( 256,256, 3), classes=3, activation='sigmoid')\n",
    "    model.compile(optimizer='Adam', loss=jacard_coef_loss, metrics = [jacard_coef, dice_coef])\n",
    "    model.fit(x=batch_generator(batchsize, generate_data(file_list[train_index], image_path, mask_path, gen_type = \"train\")), epochs=num_epoch, \n",
    "                            steps_per_epoch=(trainsize/batchsize), \n",
    "                            validation_steps=(valsize/batchsize),\n",
    "                            validation_data=batch_generator(batchsize, generate_data(file_list[val_index], image_path, mask_path, gen_type = \"val\")), \n",
    "                            validation_freq=1, \n",
    "                            verbose = 1, \n",
    "                            callbacks=[reduce_lr],\n",
    "                            )\n",
    "    val_gen  = generate_data_pred(file_list[val_index], image_path, mask_path, gen_type = \"val\")\n",
    "    for i in range(valsize):\n",
    "        time_start = time.time()\n",
    "        original_img, original_mask, X, y_true = next(val_gen)\n",
    "        original_shape = original_img.shape\n",
    "        y_pred = model.predict(np.expand_dims(X,0))\n",
    "        _,y_pred_thr = cv2.threshold(y_pred[0,:,:,0]*255, 127, 255, cv2.THRESH_BINARY)\n",
    "        y_pred = (y_pred_thr/255).astype(int)\n",
    "        dice_resized = dice_score(y_true[:,:,0],y_pred)\n",
    "        #jaccard_resized = jaccard_score(y_true[:,:,0],y_pred, average=\"macro\")\n",
    "        \n",
    "        y_pred_original = cv2.resize(y_pred.astype(float), (original_shape[1],original_shape[0]), interpolation= cv2.INTER_LINEAR)\n",
    "        dice_original = dice_score(original_mask[:,:,0],y_pred_original.astype(int)*255)\n",
    "        #jaccard_original = jaccard_score(original_mask[:,:,0],y_pred_original.astype(int)*255, average=\"macro\")\n",
    "        \n",
    "        validation_dice_original[i,cv_count] = dice_original\n",
    "        validation_dice_resized[i,cv_count] = dice_resized\n",
    "        #validation_jaccard_original[i,cv_count] = jaccard_original\n",
    "        #validation_jaccard_resized[i,cv_count] = jaccard_resized\n",
    "        \n",
    "        if i < 5:\n",
    "            plt.figure(figsize=(20,10))\n",
    "            plt.subplot(1,2,1)\n",
    "            plt.imshow(original_img, 'gray', interpolation='none')\n",
    "            plt.imshow(original_mask/255.0, 'jet', interpolation='none', alpha=0.4)\n",
    "            plt.subplot(1,2,2)\n",
    "            plt.imshow(original_img, 'gray', interpolation='none')\n",
    "            plt.imshow(y_pred_original, 'jet', interpolation='none', alpha=0.4)\n",
    "            plt.show()\n",
    "        \n",
    "    dice_resized_mean = validation_dice_resized[:,cv_count].mean()\n",
    "    dice_original_mean = validation_dice_original[:,cv_count].mean()\n",
    "    #jaccard_resized_mean = validation_jaccard_resized[:,cv_count].mean()\n",
    "    #jaccard_original_mean = validation_jaccard_original[:,cv_count].mean()\n",
    "        \n",
    "    print(\"--------------------------------------\")\n",
    "    print(\"Mean validation DICE (on resized data):\", dice_resized_mean) \n",
    "    print(\"Mean validation DICE (on original data):\", dice_original_mean)\n",
    "    print(\"--------------------------------------\")\n",
    "    #print(\"Mean validation Jaccard (on resized data):\", jaccard_resized_mean) \n",
    "    #print(\"Mean validation Jaccard (on original data):\", jaccard_original_mean)\n",
    "    #print(\"--------------------------------------\")\n",
    "    run[\"Dice Resized\"].log(dice_resized_mean)\n",
    "    run[\"Dice Original\"].log(dice_original_mean)\n",
    "    #run[\"Jaccard Resized\"].log(jaccard_resized_mean)\n",
    "    #run[\"Jaccard Original\"].log(jaccard_original_mean)\n",
    "    runtime = time.time() - time_start \n",
    "    print('Runtime: {} sec'.format(runtime))\n",
    "    run[\"Runtime\"] = runtime\n",
    "    cv_count +=1\n",
    "run.stop()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:06:12.906615Z",
     "iopub.status.busy": "2021-09-27T17:06:12.9061Z",
     "iopub.status.idle": "2021-09-27T17:06:12.916859Z",
     "shell.execute_reply": "2021-09-27T17:06:12.916255Z",
     "shell.execute_reply.started": "2021-09-27T17:06:12.906565Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_test_data(filelist, img_path):\n",
    "    while True:\n",
    "        for i in filelist:\n",
    "            X_train_orig = cv2.imread(img_path + i, cv2.IMREAD_COLOR )\n",
    "            X_train = cv2.resize(X_train_orig, (256,256), interpolation= cv2.INTER_LINEAR )\n",
    "            yield X_train, X_train_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:06:12.919129Z",
     "iopub.status.busy": "2021-09-27T17:06:12.918597Z",
     "iopub.status.idle": "2021-09-27T17:06:12.928157Z",
     "shell.execute_reply": "2021-09-27T17:06:12.927384Z",
     "shell.execute_reply.started": "2021-09-27T17:06:12.918934Z"
    }
   },
   "outputs": [],
   "source": [
    "test_file_path = \"../input/kvasir-polyp-testset/MedAI_2021_Polyp_Segmentation_Test_Dataset/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:06:12.929927Z",
     "iopub.status.busy": "2021-09-27T17:06:12.929636Z",
     "iopub.status.idle": "2021-09-27T17:06:12.97439Z",
     "shell.execute_reply": "2021-09-27T17:06:12.973756Z",
     "shell.execute_reply.started": "2021-09-27T17:06:12.929879Z"
    }
   },
   "outputs": [],
   "source": [
    "test_file_list = np.asarray(os.listdir(test_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:06:12.976378Z",
     "iopub.status.busy": "2021-09-27T17:06:12.97608Z",
     "iopub.status.idle": "2021-09-27T17:06:12.983913Z",
     "shell.execute_reply": "2021-09-27T17:06:12.983227Z",
     "shell.execute_reply.started": "2021-09-27T17:06:12.97627Z"
    }
   },
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch == 18:\n",
    "        return lr * 0.1\n",
    "    elif epoch == 20:\n",
    "        return lr * 0.1\n",
    "    else:\n",
    "        return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:06:12.987961Z",
     "iopub.status.busy": "2021-09-27T17:06:12.987712Z",
     "iopub.status.idle": "2021-09-27T17:06:12.995329Z",
     "shell.execute_reply": "2021-09-27T17:06:12.994389Z",
     "shell.execute_reply.started": "2021-09-27T17:06:12.987907Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(scheduler,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:06:12.997246Z",
     "iopub.status.busy": "2021-09-27T17:06:12.996826Z",
     "iopub.status.idle": "2021-09-27T17:20:53.830205Z",
     "shell.execute_reply": "2021-09-27T17:20:53.829347Z",
     "shell.execute_reply.started": "2021-09-27T17:06:12.997081Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b1_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n",
      "27164672/27164032 [==============================] - 0s 0us/step\n",
      "Epoch 1/30\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "34/33 [==============================] - 60s 2s/step - loss: 0.7402 - jacard_coef: 0.2598 - dice_coef: 0.8380\n",
      "Epoch 2/30\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "34/33 [==============================] - 28s 811ms/step - loss: 0.4653 - jacard_coef: 0.5347 - dice_coef: 0.9442\n",
      "Epoch 3/30\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "34/33 [==============================] - 26s 777ms/step - loss: 0.3522 - jacard_coef: 0.6478 - dice_coef: 0.9564\n",
      "Epoch 4/30\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "34/33 [==============================] - 27s 809ms/step - loss: 0.2982 - jacard_coef: 0.7018 - dice_coef: 0.9631\n",
      "Epoch 5/30\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "34/33 [==============================] - 27s 793ms/step - loss: 0.2654 - jacard_coef: 0.7346 - dice_coef: 0.9671\n",
      "Epoch 6/30\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "34/33 [==============================] - 27s 787ms/step - loss: 0.2624 - jacard_coef: 0.7376 - dice_coef: 0.9662\n",
      "Epoch 7/30\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "34/33 [==============================] - 26s 779ms/step - loss: 0.2594 - jacard_coef: 0.7406 - dice_coef: 0.9668\n",
      "Epoch 8/30\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "34/33 [==============================] - 28s 827ms/step - loss: 0.2423 - jacard_coef: 0.7577 - dice_coef: 0.9694\n",
      "Epoch 9/30\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "34/33 [==============================] - 27s 803ms/step - loss: 0.2531 - jacard_coef: 0.7469 - dice_coef: 0.9671\n",
      "Epoch 10/30\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "34/33 [==============================] - 28s 811ms/step - loss: 0.2284 - jacard_coef: 0.7716 - dice_coef: 0.9710\n",
      "Epoch 11/30\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "34/33 [==============================] - 27s 791ms/step - loss: 0.2340 - jacard_coef: 0.7660 - dice_coef: 0.9700\n",
      "Epoch 12/30\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "34/33 [==============================] - 28s 830ms/step - loss: 0.2377 - jacard_coef: 0.7623 - dice_coef: 0.9693\n",
      "Epoch 13/30\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "34/33 [==============================] - 28s 822ms/step - loss: 0.2206 - jacard_coef: 0.7794 - dice_coef: 0.9719\n",
      "Epoch 14/30\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "34/33 [==============================] - 28s 828ms/step - loss: 0.2147 - jacard_coef: 0.7853 - dice_coef: 0.9726\n",
      "Epoch 15/30\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "34/33 [==============================] - 27s 792ms/step - loss: 0.2259 - jacard_coef: 0.7741 - dice_coef: 0.9707\n",
      "Epoch 16/30\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "34/33 [==============================] - 27s 781ms/step - loss: 0.2039 - jacard_coef: 0.7961 - dice_coef: 0.9744\n",
      "Epoch 17/30\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "34/33 [==============================] - 26s 754ms/step - loss: 0.2077 - jacard_coef: 0.7923 - dice_coef: 0.9737\n",
      "Epoch 18/30\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "34/33 [==============================] - 26s 766ms/step - loss: 0.2116 - jacard_coef: 0.7884 - dice_coef: 0.9724\n",
      "Epoch 19/30\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.00010000000474974513.\n",
      "34/33 [==============================] - 27s 796ms/step - loss: 0.1963 - jacard_coef: 0.8037 - dice_coef: 0.9755\n",
      "Epoch 20/30\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.00010000000474974513.\n",
      "34/33 [==============================] - 28s 821ms/step - loss: 0.1898 - jacard_coef: 0.8102 - dice_coef: 0.9762\n",
      "Epoch 21/30\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 1.0000000474974514e-05.\n",
      "34/33 [==============================] - 27s 793ms/step - loss: 0.1845 - jacard_coef: 0.8155 - dice_coef: 0.9771\n",
      "Epoch 22/30\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 1.0000000656873453e-05.\n",
      "34/33 [==============================] - 27s 794ms/step - loss: 0.1941 - jacard_coef: 0.8059 - dice_coef: 0.9759\n",
      "Epoch 23/30\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 1.0000000656873453e-05.\n",
      "34/33 [==============================] - 28s 812ms/step - loss: 0.1869 - jacard_coef: 0.8131 - dice_coef: 0.9765\n",
      "Epoch 24/30\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 1.0000000656873453e-05.\n",
      "34/33 [==============================] - 26s 779ms/step - loss: 0.1788 - jacard_coef: 0.8212 - dice_coef: 0.9776\n",
      "Epoch 25/30\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 1.0000000656873453e-05.\n",
      "34/33 [==============================] - 28s 815ms/step - loss: 0.1841 - jacard_coef: 0.8159 - dice_coef: 0.9770\n",
      "Epoch 26/30\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 1.0000000656873453e-05.\n",
      "34/33 [==============================] - 28s 833ms/step - loss: 0.1857 - jacard_coef: 0.8143 - dice_coef: 0.9768\n",
      "Epoch 27/30\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 1.0000000656873453e-05.\n",
      "34/33 [==============================] - 27s 783ms/step - loss: 0.1765 - jacard_coef: 0.8235 - dice_coef: 0.9781\n",
      "Epoch 28/30\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 1.0000000656873453e-05.\n",
      "34/33 [==============================] - 27s 786ms/step - loss: 0.1852 - jacard_coef: 0.8148 - dice_coef: 0.9770\n",
      "Epoch 29/30\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 1.0000000656873453e-05.\n",
      "34/33 [==============================] - 28s 823ms/step - loss: 0.1798 - jacard_coef: 0.8202 - dice_coef: 0.9776\n",
      "Epoch 30/30\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 1.0000000656873453e-05.\n",
      "34/33 [==============================] - 27s 789ms/step - loss: 0.1810 - jacard_coef: 0.8190 - dice_coef: 0.9774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f8ba9c48be0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list = np.asarray(os.listdir(\"../input/hyperkvasiraugustversion/Kvasir-SEG/images\"))\n",
    "image_path = \"../input/hyperkvasiraugustversion/Kvasir-SEG/images/\" \n",
    "mask_path = \"../input/hyperkvasiraugustversion/Kvasir-SEG/masks/\"\n",
    "batchsize = 30\n",
    "data_size = len(file_list)\n",
    "num_epoch = 30\n",
    "my_model = \"efficientnetb1\"\n",
    "img_size = (256, 256)\n",
    "num_classes = 3\n",
    "#model = get_model(img_size, num_classes)\n",
    "model = sm.Unet(my_model, encoder_weights='imagenet', input_shape=( 256,256, 3), classes=3, activation='sigmoid')\n",
    "model.compile(optimizer='Adam', loss=jacard_coef_loss, metrics = [jacard_coef, dice_coef])\n",
    "model.fit(x=batch_generator(batchsize, generate_data(file_list, image_path, mask_path, gen_type = \"train\")), epochs=num_epoch, \n",
    "                        steps_per_epoch=(len(file_list)/batchsize), \n",
    "                        verbose = 1, \n",
    "                        callbacks = [lr_schedule]\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:20:53.83237Z",
     "iopub.status.busy": "2021-09-27T17:20:53.831749Z",
     "iopub.status.idle": "2021-09-27T17:20:53.836894Z",
     "shell.execute_reply": "2021-09-27T17:20:53.836207Z",
     "shell.execute_reply.started": "2021-09-27T17:20:53.832313Z"
    }
   },
   "outputs": [],
   "source": [
    "test_gen  = generate_test_data(test_file_list,test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:20:53.838952Z",
     "iopub.status.busy": "2021-09-27T17:20:53.838274Z",
     "iopub.status.idle": "2021-09-27T17:36:45.761249Z",
     "shell.execute_reply": "2021-09-27T17:36:45.757787Z",
     "shell.execute_reply.started": "2021-09-27T17:20:53.838905Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(test_file_list)):\n",
    "        test_img, original_img= next(test_gen)\n",
    "        original_shape = original_img.shape\n",
    "        y_pred = model.predict(np.expand_dims(test_img,0))\n",
    "        _,y_pred_thr = cv2.threshold(y_pred[0,:,:,0]*255, 127, 255, cv2.THRESH_BINARY)\n",
    "        y_pred = (y_pred_thr/255).astype(int)\n",
    "        y_pred_original = cv2.resize(y_pred.astype(float), (original_shape[1],original_shape[0]), interpolation= cv2.INTER_LINEAR)\n",
    "        #cv2.imwrite(\"./\" + test_file_list[i], y_pred_original)\n",
    "        imageio.imwrite(\"./\" + test_file_list[i], y_pred_original)\n",
    "        #plt.imshow(y_pred_original)\n",
    "        #plt.axis('off')\n",
    "        #plt.savefig(\"./\" + test_file_list[i],bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
