{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-09-27T17:05:39.089052Z",
     "iopub.status.busy": "2021-09-27T17:05:39.088769Z",
     "iopub.status.idle": "2021-09-27T17:05:42.72167Z",
     "shell.execute_reply": "2021-09-27T17:05:42.720849Z",
     "shell.execute_reply.started": "2021-09-27T17:05:39.089002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hyperkvasiraugustversion', 'kvasir-polyp-testset']\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import time\n",
    "from contextlib import contextmanager # timer\n",
    "from functools import partial\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.model_selection import KFold\n",
    "import random\n",
    "from skimage.transform import rescale, resize\n",
    "from scipy.ndimage import rotate\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import SimpleITK as sitk\n",
    "print(os.listdir(\"../input/\"))\n",
    "from skimage import data, img_as_float\n",
    "from skimage import exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:05:42.723904Z",
     "iopub.status.busy": "2021-09-27T17:05:42.723446Z",
     "iopub.status.idle": "2021-09-27T17:05:42.730756Z",
     "shell.execute_reply": "2021-09-27T17:05:42.729959Z",
     "shell.execute_reply.started": "2021-09-27T17:05:42.723854Z"
    }
   },
   "outputs": [],
   "source": [
    "def batch_generator(batch_size, gen_x): \n",
    "    batch_features = np.zeros((batch_size,256,256,3))\n",
    "    batch_labels = np.zeros((batch_size,256,256,3)) \n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            batch_features[i] , batch_labels[i] = next(gen_x)\n",
    "        yield batch_features, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:05:42.732944Z",
     "iopub.status.busy": "2021-09-27T17:05:42.73244Z",
     "iopub.status.idle": "2021-09-27T17:05:42.761414Z",
     "shell.execute_reply": "2021-09-27T17:05:42.760393Z",
     "shell.execute_reply.started": "2021-09-27T17:05:42.732716Z"
    }
   },
   "outputs": [],
   "source": [
    "def gaussian_noise(img, mean=0, sigma=0.03):\n",
    "    img = img.copy()\n",
    "    noise = np.random.normal(mean, sigma, img.shape)\n",
    "    mask_overflow_upper = img+noise >= 1.0\n",
    "    mask_overflow_lower = img+noise < 0\n",
    "    noise[mask_overflow_upper] = 1.0\n",
    "    noise[mask_overflow_lower] = 0\n",
    "    img += noise\n",
    "    return img\n",
    "\n",
    "#https://towardsdatascience.com/complete-image-augmentation-in-opencv-31a6b02694f5\n",
    "def brightness(img, low, high):\n",
    "    value = random.uniform(low, high)\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    hsv = np.array(hsv, dtype = np.float64)\n",
    "    hsv[:,:,1] = hsv[:,:,1]*value\n",
    "    hsv[:,:,1][hsv[:,:,1]>255]  = 255\n",
    "    hsv[:,:,2] = hsv[:,:,2]*value \n",
    "    hsv[:,:,2][hsv[:,:,2]>255]  = 255\n",
    "    hsv = np.array(hsv, dtype = np.uint8)\n",
    "    img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    return img\n",
    "\n",
    "#https://towardsdatascience.com/complete-image-augmentation-in-opencv-31a6b02694f5\n",
    "def fill(img, h, w):\n",
    "    img = img.astype('float32')\n",
    "    img = cv2.resize(img, (h, w), cv2.INTER_CUBIC)\n",
    "    return img\n",
    "def zoom(img, mask, value):\n",
    "    if value > 1 or value < 0:\n",
    "        print('Value for zoom should be less than 1 and greater than 0')\n",
    "        return img, mask\n",
    "    value = random.uniform(value, 1)\n",
    "    h, w = img.shape[:2]\n",
    "    h_taken = int(value*h)\n",
    "    w_taken = int(value*w)\n",
    "    h_start = random.randint(0, h-h_taken)\n",
    "    w_start = random.randint(0, w-w_taken)\n",
    "    img = img[h_start:h_start+h_taken, w_start:w_start+w_taken, :]\n",
    "    img = fill(img, h, w)\n",
    "    mask = mask[h_start:h_start+h_taken, w_start:w_start+w_taken, :]\n",
    "    mask = fill(mask, h, w)\n",
    "    return img, mask\n",
    "\n",
    "# https://towardsdatascience.com/complete-image-augmentation-in-opencv-31a6b02694f5\n",
    "def vertical_shift(img, mask, ratio=0.0):\n",
    "    if ratio > 1 or ratio < 0:\n",
    "        print('Value should be less than 1 and greater than 0')\n",
    "        return img, mask\n",
    "    ratio = random.uniform(-ratio, ratio)\n",
    "    h, w = img.shape[:2]\n",
    "    to_shift = h*ratio\n",
    "    if ratio > 0:\n",
    "        img = img[:, :int(w-to_shift), :]\n",
    "        mask = mask[:, :int(w-to_shift), :]\n",
    "    if ratio < 0:\n",
    "        img = img[:, int(-1*to_shift):, :]\n",
    "        mask = mask[:, int(-1*to_shift):, :]\n",
    "    img = fill(img, h, w)\n",
    "    mask = fill(mask, h, w)\n",
    "    return img, mask\n",
    "\n",
    "# https://towardsdatascience.com/complete-image-augmentation-in-opencv-31a6b02694f5 \n",
    "def horizontal_shift(img, mask, ratio=0.0):\n",
    "    if ratio > 1 or ratio < 0:\n",
    "        print('Value should be less than 1 and greater than 0')\n",
    "        return img, mask\n",
    "    ratio = random.uniform(-ratio, ratio)\n",
    "    h, w = img.shape[:2]\n",
    "    to_shift = w*ratio\n",
    "    if ratio > 0:\n",
    "        img = img[:, :int(w-to_shift), :]\n",
    "        mask = mask[:, :int(w-to_shift), :]\n",
    "    if ratio < 0:\n",
    "        img = img[:, int(-1*to_shift):, :]\n",
    "        mask = mask[:, int(-1*to_shift):, :]\n",
    "    img = fill(img, h, w)\n",
    "    mask = fill(mask, h, w)\n",
    "    return img,mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:05:42.764939Z",
     "iopub.status.busy": "2021-09-27T17:05:42.76465Z",
     "iopub.status.idle": "2021-09-27T17:05:42.783544Z",
     "shell.execute_reply": "2021-09-27T17:05:42.78274Z",
     "shell.execute_reply.started": "2021-09-27T17:05:42.764846Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_data(filelist, img_path, mask_path, gen_type = \"train\"):\n",
    "    while True:\n",
    "        for i in filelist:\n",
    "            X_train = cv2.imread(img_path + i, cv2.IMREAD_COLOR )\n",
    "            X_train = cv2.resize(X_train, (256,256), interpolation= cv2.INTER_LINEAR )\n",
    "            y_mask = cv2.imread(mask_path + i, cv2.IMREAD_COLOR)\n",
    "            y_mask = cv2.resize(y_mask, (256,256), interpolation= cv2.IMREAD_GRAYSCALE)\n",
    "            _,y_mask = cv2.threshold(y_mask, 127, 255, cv2.THRESH_BINARY)\n",
    "            y_train = (y_mask/255).astype(int)\n",
    "            if gen_type == \"train\":\n",
    "                # returns a random integer used to select augmentataion techniques for a given sample\n",
    "                augment_num = np.random.randint(0,9)\n",
    "                if augment_num == 0:\n",
    "                    # do nothing\n",
    "                    X_train = X_train\n",
    "                elif augment_num == 1:\n",
    "                    #random noise\n",
    "                    X_train = X_train + np.random.rand(X_train.shape[0], X_train.shape[1], X_train.shape[2])*np.random.randint(-100,100)\n",
    "                elif augment_num == 2:\n",
    "                    X_train = cv2.GaussianBlur(X_train,(random.randrange(1,50,2),random.randrange(1,50,2)), 0)\n",
    "                elif augment_num == 3:\n",
    "                    rot = np.random.randint(-45,45)\n",
    "                    X_train = rotate(X_train,rot, reshape=False)\n",
    "                    y_train = rotate(y_train,rot, reshape=False)\n",
    "                elif augment_num == 4:\n",
    "                    X_train = brightness(X_train,0.5,3)\n",
    "                elif augment_num == 5:\n",
    "                    X_train = np.fliplr(X_train)\n",
    "                    y_train = np.fliplr(y_train)\n",
    "                elif augment_num == 6:\n",
    "                    X_train = np.flipud(X_train)\n",
    "                    y_train = np.flipud(y_train)\n",
    "                elif augment_num == 7:\n",
    "                    hshift = round(random.uniform(0.1, 0.3),3)\n",
    "                    X_train, y_train = horizontal_shift(X_train, y_train, hshift)\n",
    "                elif augment_num == 8:\n",
    "                    vshift = round(random.uniform(0.1, 0.3),3)\n",
    "                    X_train, y_train = vertical_shift(X_train, y_train, vshift)\n",
    "                elif augment_num == 9:\n",
    "                    zoom_rate = round(random.uniform(0.8, 0.95),3)\n",
    "                    X_train, y_train = zoom(X_train, y_train, zoom_rate)\n",
    "                elif augment_num == 10:\n",
    "                    #contrast\n",
    "                    X_train = exposure.equalize_adapthist(X_train.astype(int), clip_limit=0.03)  \n",
    "                elif augment_num == 11:\n",
    "                    #contrast\n",
    "                    X_train = exposure.equalize_hist(X_train.astype(int))  \n",
    "            yield X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:05:42.787949Z",
     "iopub.status.busy": "2021-09-27T17:05:42.787415Z",
     "iopub.status.idle": "2021-09-27T17:05:42.797918Z",
     "shell.execute_reply": "2021-09-27T17:05:42.79679Z",
     "shell.execute_reply.started": "2021-09-27T17:05:42.787898Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_data_pred(filelist, img_path, mask_path, gen_type = \"train\"):\n",
    "    while True:\n",
    "        for i in filelist:\n",
    "            original_img = cv2.imread(img_path + i, cv2.IMREAD_COLOR )\n",
    "            X_train = cv2.resize(original_img, (256,256), interpolation= cv2.INTER_LINEAR )\n",
    "            if gen_type == \"train\":\n",
    "                X_train = X_train * np.random.choice([1,1,1,np.random.rand(256, 256,3)])\n",
    "            original_mask = cv2.imread(mask_path + i, cv2.IMREAD_COLOR)\n",
    "            y_mask = cv2.resize(original_mask, (256,256), interpolation= cv2.IMREAD_GRAYSCALE)\n",
    "            _,y_mask = cv2.threshold(y_mask, 127, 255, cv2.THRESH_BINARY)\n",
    "            y_mask = (y_mask/255).astype(int)\n",
    "            yield original_img, original_mask, X_train, y_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:05:42.801191Z",
     "iopub.status.busy": "2021-09-27T17:05:42.800673Z",
     "iopub.status.idle": "2021-09-27T17:05:42.808672Z",
     "shell.execute_reply": "2021-09-27T17:05:42.807882Z",
     "shell.execute_reply.started": "2021-09-27T17:05:42.800932Z"
    }
   },
   "outputs": [],
   "source": [
    "def dice_score(mask_gt, mask_pred):\n",
    "    \"\"\"Computes soerensen-dice coefficient.\n",
    "\n",
    "    compute the soerensen-dice coefficient between the ground truth mask `mask_gt`\n",
    "    and the predicted mask `mask_pred`.\n",
    "\n",
    "    Args:\n",
    "    mask_gt: 3-dim Numpy array of type bool. The ground truth mask.\n",
    "    mask_pred: 3-dim Numpy array of type bool. The predicted mask.\n",
    "\n",
    "    Returns:\n",
    "    the dice coeffcient as float. If both masks are empty, the result is NaN.\n",
    "    \"\"\"\n",
    "    volume_sum = mask_gt.sum() + mask_pred.sum()\n",
    "    if volume_sum == 0:\n",
    "        return np.NaN\n",
    "    volume_intersect = (mask_gt & mask_pred).sum()\n",
    "    return 2*volume_intersect / volume_sum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:05:42.810554Z",
     "iopub.status.busy": "2021-09-27T17:05:42.810022Z",
     "iopub.status.idle": "2021-09-27T17:05:44.345213Z",
     "shell.execute_reply": "2021-09-27T17:05:44.344487Z",
     "shell.execute_reply.started": "2021-09-27T17:05:42.810503Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "# From: https://gist.github.com/wassname/7793e2058c5c9dacb5212c0ac0b18a8a\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    \"\"\"\n",
    "    Dice = (2*|X & Y|)/ (|X|+ |Y|)\n",
    "         =  2*sum(|A*B|)/(sum(A^2)+sum(B^2))\n",
    "    ref: https://arxiv.org/pdf/1606.04797v1.pdf\n",
    "    \"\"\"\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    return (2. * intersection + smooth) / (K.sum(K.square(y_true),-1) + K.sum(K.square(y_pred),-1) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:05:44.346848Z",
     "iopub.status.busy": "2021-09-27T17:05:44.346585Z",
     "iopub.status.idle": "2021-09-27T17:05:44.360838Z",
     "shell.execute_reply": "2021-09-27T17:05:44.359768Z",
     "shell.execute_reply.started": "2021-09-27T17:05:44.346806Z"
    }
   },
   "outputs": [],
   "source": [
    "def jacard_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
    "\n",
    "\n",
    "def jacard_coef_loss(y_true, y_pred):\n",
    "    return 1-jacard_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:05:44.363193Z",
     "iopub.status.busy": "2021-09-27T17:05:44.362847Z",
     "iopub.status.idle": "2021-09-27T17:05:44.413335Z",
     "shell.execute_reply": "2021-09-27T17:05:44.412527Z",
     "shell.execute_reply.started": "2021-09-27T17:05:44.363117Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def get_model(img_size, num_classes):\n",
    "\n",
    "    inputs = tf.keras.Input(shape=img_size + (3,))\n",
    "    #inputs = tf.keras.Input(shape=(256,256,3))\n",
    "    #inputs = tf.keras.Input(shape=img_size + (1,))\n",
    "    ### [First half of the network: downsampling inputs] ###\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
    "    for filters in [64, 128, 256]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    ### [Second half of the network: upsampling inputs] ###\n",
    "\n",
    "    for filters in [256, 128, 64, 32]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.UpSampling2D(2)(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.UpSampling2D(2)(previous_block_activation)\n",
    "        residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    # Add a per-pixel classification layer\n",
    "    outputs = layers.Conv2D(num_classes, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "\n",
    "    # Define the model\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=jacard_coef_loss, metrics = [jacard_coef, dice_coef])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Free up RAM in case the model definition cells were run multiple times\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Build model\n",
    "#model = get_model(img_size, num_classes)\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:05:44.415042Z",
     "iopub.status.busy": "2021-09-27T17:05:44.414655Z",
     "iopub.status.idle": "2021-09-27T17:05:44.420506Z",
     "shell.execute_reply": "2021-09-27T17:05:44.419485Z",
     "shell.execute_reply.started": "2021-09-27T17:05:44.414998Z"
    }
   },
   "outputs": [],
   "source": [
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.1, patience=3, verbose=1, mode='min',\n",
    "    min_delta=0.0001, cooldown=5, min_lr=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:05:44.422676Z",
     "iopub.status.busy": "2021-09-27T17:05:44.422136Z",
     "iopub.status.idle": "2021-09-27T17:05:52.114449Z",
     "shell.execute_reply": "2021-09-27T17:05:52.113677Z",
     "shell.execute_reply.started": "2021-09-27T17:05:44.422396Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting segmentation-models==1.0.1\r\n",
      "  Downloading https://files.pythonhosted.org/packages/da/b9/4a183518c21689a56b834eaaa45cad242d9ec09a4360b5b10139f23c63f4/segmentation_models-1.0.1-py3-none-any.whl\r\n",
      "Collecting image-classifiers==1.0.0 (from segmentation-models==1.0.1)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/81/98/6f84720e299a4942ab80df5f76ab97b7828b24d1de5e9b2cbbe6073228b7/image_classifiers-1.0.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /opt/conda/lib/python3.6/site-packages (from segmentation-models==1.0.1) (1.0.8)\r\n",
      "Collecting efficientnet==1.0.0 (from segmentation-models==1.0.1)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/97/82/f3ae07316f0461417dc54affab6e86ab188a5a22f33176d35271628b96e0/efficientnet-1.0.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models==1.0.1) (1.16.4)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models==1.0.1) (2.9.0)\r\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.6/site-packages (from efficientnet==1.0.0->segmentation-models==1.0.1) (0.15.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation-models==1.0.1) (1.12.0)\r\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (2.3)\r\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (1.0.3)\r\n",
      "Requirement already satisfied: pillow>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (5.4.1)\r\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (3.0.3)\r\n",
      "Requirement already satisfied: imageio>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (2.5.0)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from networkx>=2.0->scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (4.4.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (0.10.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (1.1.0)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (2.4.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (2.8.0)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (41.2.0)\r\n",
      "Installing collected packages: image-classifiers, efficientnet, segmentation-models\r\n",
      "Successfully installed efficientnet-1.0.0 image-classifiers-1.0.0 segmentation-models-1.0.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install segmentation-models==1.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:05:52.116286Z",
     "iopub.status.busy": "2021-09-27T17:05:52.116006Z",
     "iopub.status.idle": "2021-09-27T17:05:52.140965Z",
     "shell.execute_reply": "2021-09-27T17:05:52.140205Z",
     "shell.execute_reply.started": "2021-09-27T17:05:52.116239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import segmentation_models as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:05:52.142554Z",
     "iopub.status.busy": "2021-09-27T17:05:52.142246Z",
     "iopub.status.idle": "2021-09-27T17:06:12.650457Z",
     "shell.execute_reply": "2021-09-27T17:06:12.649701Z",
     "shell.execute_reply.started": "2021-09-27T17:05:52.142507Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting neptune-client\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/97/4e5b5d848c9c3fa604825d92c239a45bd56db602bdce21c34f117db97395/neptune-client-0.11.0.tar.gz (269kB)\r\n",
      "\u001b[K     |████████████████████████████████| 276kB 595kB/s \r\n",
      "\u001b[?25hCollecting bravado (from neptune-client)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/21/ed/03b0c36b5bcafbe2938ed222f9a164a6c0367ce99a9d2d502e462853571d/bravado-11.0.3-py2.py3-none-any.whl\r\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.6/site-packages (from neptune-client) (7.0)\r\n",
      "Requirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.6/site-packages (from neptune-client) (0.17.1)\r\n",
      "Collecting oauthlib>=2.1.0 (from neptune-client)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/5d/9dd1c29e5a786525f6342f6c1d812ed2e37edc653ad297048c1668988053/oauthlib-3.1.1-py2.py3-none-any.whl (146kB)\r\n",
      "\u001b[K     |████████████████████████████████| 153kB 8.4MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from neptune-client) (0.25.1)\r\n",
      "Requirement already satisfied: Pillow>=1.1.6 in /opt/conda/lib/python3.6/site-packages (from neptune-client) (5.4.1)\r\n",
      "Collecting PyJWT (from neptune-client)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/3f/32/d5d3cab27fee7f6b22d7cd7507547ae45d52e26030fa77d1f83d0526c6e5/PyJWT-2.1.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: requests>=2.20.0 in /opt/conda/lib/python3.6/site-packages (from neptune-client) (2.22.0)\r\n",
      "Collecting requests-oauthlib>=1.0.0 (from neptune-client)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\r\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from neptune-client) (1.12.0)\r\n",
      "Requirement already satisfied: websocket-client!=1.0.0,>=0.35.0 in /opt/conda/lib/python3.6/site-packages (from neptune-client) (0.56.0)\r\n",
      "Collecting GitPython>=2.0.8 (from neptune-client)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/91/b38c4fabb6e5092ab23492ded4f318ab7299b19263272b703478038c0fbc/GitPython-3.1.18-py3-none-any.whl (170kB)\r\n",
      "\u001b[K     |████████████████████████████████| 174kB 7.4MB/s \r\n",
      "\u001b[?25hCollecting boto3>=1.16.0 (from neptune-client)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/90/04fa79a9c0cf7650d92bf1dcb12ddf1df38fd970bba615712b613b40751a/boto3-1.18.48-py3-none-any.whl (131kB)\r\n",
      "\u001b[K     |████████████████████████████████| 133kB 9.2MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from neptune-client) (19.2)\r\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.6/site-packages (from neptune-client) (1.24.2)\r\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.6/site-packages (from neptune-client) (5.6.3)\r\n",
      "Requirement already satisfied: dataclasses>=0.6 in /opt/conda/lib/python3.6/site-packages (from neptune-client) (0.6)\r\n",
      "Collecting bravado-core>=5.16.1 (from bravado->neptune-client)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/11/18e9d28a156c33f2d5f15a5e155dc7130250acb0a569255a2b6b307b596d/bravado_core-5.17.0-py2.py3-none-any.whl (67kB)\r\n",
      "\u001b[K     |████████████████████████████████| 71kB 8.7MB/s \r\n",
      "\u001b[?25hCollecting simplejson (from bravado->neptune-client)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/84/646d5238bddd2e436a9a6bacd260ef85626825ebe359ef807adf259c9233/simplejson-3.17.5-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (129kB)\r\n",
      "\u001b[K     |████████████████████████████████| 133kB 8.1MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from bravado->neptune-client) (5.1.2)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.6/site-packages (from bravado->neptune-client) (3.6.6)\r\n",
      "Requirement already satisfied: msgpack in /opt/conda/lib/python3.6/site-packages (from bravado->neptune-client) (0.6.1)\r\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.6/site-packages (from bravado->neptune-client) (2.8.0)\r\n",
      "Requirement already satisfied: monotonic in /opt/conda/lib/python3.6/site-packages (from bravado->neptune-client) (1.5)\r\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas->neptune-client) (2019.2)\r\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.6/site-packages (from pandas->neptune-client) (1.16.4)\r\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests>=2.20.0->neptune-client) (3.0.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests>=2.20.0->neptune-client) (2019.9.11)\r\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests>=2.20.0->neptune-client) (2.8)\r\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython>=2.0.8->neptune-client)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\r\n",
      "\u001b[K     |████████████████████████████████| 71kB 10.1MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.16.0->neptune-client) (0.9.4)\r\n",
      "Collecting s3transfer<0.6.0,>=0.5.0 (from boto3>=1.16.0->neptune-client)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/84/fc3717a7b7f0f6bb08af593127171f08e3e0087c197922da09c01bfe7c3a/s3transfer-0.5.0-py3-none-any.whl (79kB)\r\n",
      "\u001b[K     |████████████████████████████████| 81kB 8.5MB/s \r\n",
      "\u001b[?25hCollecting botocore<1.22.0,>=1.21.48 (from boto3>=1.16.0->neptune-client)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/85/fb43104a56d9b53cb7f8fe4ad5cc5a79210a91906930fd926b74cc660cb4/botocore-1.21.48-py3-none-any.whl (7.9MB)\r\n",
      "\u001b[K     |████████████████████████████████| 7.9MB 8.4MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging->neptune-client) (2.4.2)\r\n",
      "Requirement already satisfied: jsonschema[format]>=2.5.1 in /opt/conda/lib/python3.6/site-packages (from bravado-core>=5.16.1->bravado->neptune-client) (3.0.2)\r\n",
      "Collecting jsonref (from bravado-core>=5.16.1->bravado->neptune-client)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/07/92/f8e4ac824b14af77e613984e480fa818397c72d4141fc466decb26752749/jsonref-0.2-py3-none-any.whl\r\n",
      "Collecting swagger-spec-validator>=2.0.1 (from bravado-core>=5.16.1->bravado->neptune-client)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/09/de/e78cefbf5838b434b63a789264b79821cb2267f1498fbed23ef8590133e4/swagger_spec_validator-2.7.3-py2.py3-none-any.whl\r\n",
      "Collecting smmap<5,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython>=2.0.8->neptune-client)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\r\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.6/site-packages (from jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado->neptune-client) (19.1.0)\r\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.6/site-packages (from jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado->neptune-client) (0.15.4)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado->neptune-client) (41.2.0)\r\n",
      "Collecting rfc3987; extra == \"format\" (from jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado->neptune-client)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/65/d4/f7407c3d15d5ac779c3dd34fbbc6ea2090f77bd7dd12f207ccf881551208/rfc3987-1.3.8-py2.py3-none-any.whl\r\n",
      "Collecting strict-rfc3339; extra == \"format\" (from jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado->neptune-client)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/56/e4/879ef1dbd6ddea1c77c0078cd59b503368b0456bcca7d063a870ca2119d3/strict-rfc3339-0.7.tar.gz\r\n",
      "Collecting webcolors; extra == \"format\" (from jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado->neptune-client)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/12/05/3350559de9714b202e443a9e6312937341bd5f79f4e4f625744295e7dd17/webcolors-1.11.1-py3-none-any.whl\r\n",
      "Collecting jsonpointer>1.13; extra == \"format\" (from jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado->neptune-client)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/23/52/05f67532aa922e494c351344e0d9624a01f74f5dd8402fe0d1b563a6e6fc/jsonpointer-2.1-py2.py3-none-any.whl\r\n",
      "Building wheels for collected packages: neptune-client, strict-rfc3339\r\n",
      "  Building wheel for neptune-client (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Created wheel for neptune-client: filename=neptune_client-0.11.0-py2.py3-none-any.whl size=465803 sha256=ab6f60109bbf6ea64b239616d6401cae52747e43cb97db8075bfa9a392f5c2ba\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/63/87/d0/853bd5c944c55c458935ac35da8eb5f9e0d1d428725a549666\r\n",
      "  Building wheel for strict-rfc3339 (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for strict-rfc3339: filename=strict_rfc3339-0.7-cp36-none-any.whl size=18121 sha256=14241f1e740e2dc315ab303dcab9cad2e3d7eaeec2337904bf36c90ed2e22594\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/bb/af/c9/b6e9fb5f9b2470e4ed2a7241c9ab3a8cdd3bc8555ae02ca2e6\r\n",
      "Successfully built neptune-client strict-rfc3339\r\n",
      "\u001b[31mERROR: allennlp 0.9.0 requires flaky, which is not installed.\u001b[0m\r\n",
      "\u001b[31mERROR: allennlp 0.9.0 requires responses>=0.7, which is not installed.\u001b[0m\r\n",
      "\u001b[31mERROR: botocore 1.21.48 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.2 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mERROR: gitpython 3.1.18 has requirement typing-extensions>=3.7.4.0; python_version < \"3.8\", but you'll have typing-extensions 3.6.6 which is incompatible.\u001b[0m\r\n",
      "Installing collected packages: simplejson, jsonref, swagger-spec-validator, bravado-core, bravado, oauthlib, PyJWT, requests-oauthlib, smmap, gitdb, GitPython, botocore, s3transfer, boto3, neptune-client, rfc3987, strict-rfc3339, webcolors, jsonpointer\r\n",
      "  Found existing installation: botocore 1.12.237\r\n",
      "    Uninstalling botocore-1.12.237:\r\n",
      "      Successfully uninstalled botocore-1.12.237\r\n",
      "  Found existing installation: s3transfer 0.2.1\r\n",
      "    Uninstalling s3transfer-0.2.1:\r\n",
      "      Successfully uninstalled s3transfer-0.2.1\r\n",
      "  Found existing installation: boto3 1.9.237\r\n",
      "    Uninstalling boto3-1.9.237:\r\n",
      "      Successfully uninstalled boto3-1.9.237\r\n",
      "Successfully installed GitPython-3.1.18 PyJWT-2.1.0 boto3-1.18.48 botocore-1.21.48 bravado-11.0.3 bravado-core-5.17.0 gitdb-4.0.7 jsonpointer-2.1 jsonref-0.2 neptune-client-0.11.0 oauthlib-3.1.1 requests-oauthlib-1.3.0 rfc3987-1.3.8 s3transfer-0.5.0 simplejson-3.17.5 smmap-4.0.0 strict-rfc3339-0.7 swagger-spec-validator-2.7.3 webcolors-1.11.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install neptune-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:06:12.654813Z",
     "iopub.status.busy": "2021-09-27T17:06:12.654536Z",
     "iopub.status.idle": "2021-09-27T17:06:12.889422Z",
     "shell.execute_reply": "2021-09-27T17:06:12.888748Z",
     "shell.execute_reply.started": "2021-09-27T17:06:12.654755Z"
    }
   },
   "outputs": [],
   "source": [
    "import neptune.new as neptune\n",
    "from sklearn.metrics import jaccard_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:06:12.891807Z",
     "iopub.status.busy": "2021-09-27T17:06:12.891284Z",
     "iopub.status.idle": "2021-09-27T17:06:12.904756Z",
     "shell.execute_reply": "2021-09-27T17:06:12.904047Z",
     "shell.execute_reply.started": "2021-09-27T17:06:12.891758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfile_list = np.asarray(os.listdir(\"../input/hyperkvasiraugustversion/Kvasir-SEG/images\"))\\nimage_path = \"../input/hyperkvasiraugustversion/Kvasir-SEG/images/\" \\nmask_path = \"../input/hyperkvasiraugustversion/Kvasir-SEG/masks/\"\\n\\nrun = neptune.init(project=\\'SSCP/HyperKvasir\\',\\n                   api_token=\\'eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIzMGUyN2Q2ZS05MjVkLTRlMzItODYwZS0yODQ3ZWU3ZTdmMmEifQ==\\') # your credentials\\n\\n\\nbatchsize = 10\\ndata_size = len(file_list)\\nnum_epoch = 25\\nsplits = 10\\nkf = KFold(n_splits=splits)\\nvalsize = data_size // splits\\ntrainsize = data_size - valsize\\nmy_model = \"efficientnetb0\"\\ndata_num = np.arange(data_size)\\n\\nimg_size = (256, 256)\\nnum_classes = 3\\n\\nrun[\"Dataset\"] = \"Polyp\"\\nrun[\"Model\"] = my_model\\nrun[\"CV-folds\"] = splits\\nrun[\"Epochs\"] = num_epoch\\nrun[\"Batch size\"] = batchsize\\nrun[\"pretrained\"] = \"Imagenet\"\\n##########################################################################################\\n# Check what augmentation techniques you use and say \"yes\" or \"no\" in the fields bellow  #\\n# You can also add new fields                                                            #\\n##########################################################################################\\nrun[\"noise\"] = \"yes\"\\nrun[\"blurring\"] = \"yes\"\\nrun[\"cropping\"] = \"no\"\\nrun[\"flipping\"] = \"yes\"\\nrun[\"rotation\"] = \"yes\"\\nrun[\"zoom\"] = \"yes\"\\nrun[\"translation\"] = \"no\"\\nrun[\"brightness\"] = \"yes\"\\nrun[\"contrast_hist\"] = \"no\"\\nrun[\"contrast_adaptive\"] = \"no\"\\nrun[\"color augmentation\"] = \"no\"\\nrun[\"saturation\"] =\"no\"\\nrun[\"horizontal shift\"] = \"yes\"\\nrun[\"vertical shift\"] = \"yes\"\\n\\nvalidation_dice_original = np.zeros([valsize,splits])\\nvalidation_dice_resized = np.zeros([valsize,splits])\\n#validation_jaccard_original = np.zeros([valsize,splits])\\n#validation_jaccard_resized = np.zeros([valsize,splits])\\n\\ncv_count = 0\\n\\nfor train_index, val_index in kf.split(data_num):\\n    #model = get_model(img_size, num_classes)\\n    model = sm.Unet(my_model, encoder_weights=\\'imagenet\\', input_shape=( 256,256, 3), classes=3, activation=\\'sigmoid\\')\\n    model.compile(optimizer=\\'Adam\\', loss=jacard_coef_loss, metrics = [jacard_coef, dice_coef])\\n    model.fit(x=batch_generator(batchsize, generate_data(file_list[train_index], image_path, mask_path, gen_type = \"train\")), epochs=num_epoch, \\n                            steps_per_epoch=(trainsize/batchsize), \\n                            validation_steps=(valsize/batchsize),\\n                            validation_data=batch_generator(batchsize, generate_data(file_list[val_index], image_path, mask_path, gen_type = \"val\")), \\n                            validation_freq=1, \\n                            verbose = 1, \\n                            callbacks=[reduce_lr],\\n                            )\\n    val_gen  = generate_data_pred(file_list[val_index], image_path, mask_path, gen_type = \"val\")\\n    for i in range(valsize):\\n        time_start = time.time()\\n        original_img, original_mask, X, y_true = next(val_gen)\\n        original_shape = original_img.shape\\n        y_pred = model.predict(np.expand_dims(X,0))\\n        _,y_pred_thr = cv2.threshold(y_pred[0,:,:,0]*255, 127, 255, cv2.THRESH_BINARY)\\n        y_pred = (y_pred_thr/255).astype(int)\\n        dice_resized = dice_score(y_true[:,:,0],y_pred)\\n        #jaccard_resized = jaccard_score(y_true[:,:,0],y_pred, average=\"macro\")\\n        \\n        y_pred_original = cv2.resize(y_pred.astype(float), (original_shape[1],original_shape[0]), interpolation= cv2.INTER_LINEAR)\\n        dice_original = dice_score(original_mask[:,:,0],y_pred_original.astype(int)*255)\\n        #jaccard_original = jaccard_score(original_mask[:,:,0],y_pred_original.astype(int)*255, average=\"macro\")\\n        \\n        validation_dice_original[i,cv_count] = dice_original\\n        validation_dice_resized[i,cv_count] = dice_resized\\n        #validation_jaccard_original[i,cv_count] = jaccard_original\\n        #validation_jaccard_resized[i,cv_count] = jaccard_resized\\n        \\n        if i < 5:\\n            plt.figure(figsize=(20,10))\\n            plt.subplot(1,2,1)\\n            plt.imshow(original_img, \\'gray\\', interpolation=\\'none\\')\\n            plt.imshow(original_mask/255.0, \\'jet\\', interpolation=\\'none\\', alpha=0.4)\\n            plt.subplot(1,2,2)\\n            plt.imshow(original_img, \\'gray\\', interpolation=\\'none\\')\\n            plt.imshow(y_pred_original, \\'jet\\', interpolation=\\'none\\', alpha=0.4)\\n            plt.show()\\n        \\n    dice_resized_mean = validation_dice_resized[:,cv_count].mean()\\n    dice_original_mean = validation_dice_original[:,cv_count].mean()\\n    #jaccard_resized_mean = validation_jaccard_resized[:,cv_count].mean()\\n    #jaccard_original_mean = validation_jaccard_original[:,cv_count].mean()\\n        \\n    print(\"--------------------------------------\")\\n    print(\"Mean validation DICE (on resized data):\", dice_resized_mean) \\n    print(\"Mean validation DICE (on original data):\", dice_original_mean)\\n    print(\"--------------------------------------\")\\n    #print(\"Mean validation Jaccard (on resized data):\", jaccard_resized_mean) \\n    #print(\"Mean validation Jaccard (on original data):\", jaccard_original_mean)\\n    #print(\"--------------------------------------\")\\n    run[\"Dice Resized\"].log(dice_resized_mean)\\n    run[\"Dice Original\"].log(dice_original_mean)\\n    #run[\"Jaccard Resized\"].log(jaccard_resized_mean)\\n    #run[\"Jaccard Original\"].log(jaccard_original_mean)\\n    runtime = time.time() - time_start \\n    print(\\'Runtime: {} sec\\'.format(runtime))\\n    run[\"Runtime\"] = runtime\\n    cv_count +=1\\nrun.stop()\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "file_list = np.asarray(os.listdir(\"../input/hyperkvasiraugustversion/Kvasir-SEG/images\"))\n",
    "image_path = \"../input/hyperkvasiraugustversion/Kvasir-SEG/images/\" \n",
    "mask_path = \"../input/hyperkvasiraugustversion/Kvasir-SEG/masks/\"\n",
    "\n",
    "run = neptune.init(project='SSCP/HyperKvasir',\n",
    "                   api_token='eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIzMGUyN2Q2ZS05MjVkLTRlMzItODYwZS0yODQ3ZWU3ZTdmMmEifQ==') # your credentials\n",
    "\n",
    "\n",
    "batchsize = 10\n",
    "data_size = len(file_list)\n",
    "num_epoch = 25\n",
    "splits = 10\n",
    "kf = KFold(n_splits=splits)\n",
    "valsize = data_size // splits\n",
    "trainsize = data_size - valsize\n",
    "my_model = \"efficientnetb0\"\n",
    "data_num = np.arange(data_size)\n",
    "\n",
    "img_size = (256, 256)\n",
    "num_classes = 3\n",
    "\n",
    "run[\"Dataset\"] = \"Polyp\"\n",
    "run[\"Model\"] = my_model\n",
    "run[\"CV-folds\"] = splits\n",
    "run[\"Epochs\"] = num_epoch\n",
    "run[\"Batch size\"] = batchsize\n",
    "run[\"pretrained\"] = \"Imagenet\"\n",
    "##########################################################################################\n",
    "# Check what augmentation techniques you use and say \"yes\" or \"no\" in the fields bellow  #\n",
    "# You can also add new fields                                                            #\n",
    "##########################################################################################\n",
    "run[\"noise\"] = \"yes\"\n",
    "run[\"blurring\"] = \"yes\"\n",
    "run[\"cropping\"] = \"no\"\n",
    "run[\"flipping\"] = \"yes\"\n",
    "run[\"rotation\"] = \"yes\"\n",
    "run[\"zoom\"] = \"yes\"\n",
    "run[\"translation\"] = \"no\"\n",
    "run[\"brightness\"] = \"yes\"\n",
    "run[\"contrast_hist\"] = \"no\"\n",
    "run[\"contrast_adaptive\"] = \"no\"\n",
    "run[\"color augmentation\"] = \"no\"\n",
    "run[\"saturation\"] =\"no\"\n",
    "run[\"horizontal shift\"] = \"yes\"\n",
    "run[\"vertical shift\"] = \"yes\"\n",
    "\n",
    "validation_dice_original = np.zeros([valsize,splits])\n",
    "validation_dice_resized = np.zeros([valsize,splits])\n",
    "#validation_jaccard_original = np.zeros([valsize,splits])\n",
    "#validation_jaccard_resized = np.zeros([valsize,splits])\n",
    "\n",
    "cv_count = 0\n",
    "\n",
    "for train_index, val_index in kf.split(data_num):\n",
    "    #model = get_model(img_size, num_classes)\n",
    "    model = sm.Unet(my_model, encoder_weights='imagenet', input_shape=( 256,256, 3), classes=3, activation='sigmoid')\n",
    "    model.compile(optimizer='Adam', loss=jacard_coef_loss, metrics = [jacard_coef, dice_coef])\n",
    "    model.fit(x=batch_generator(batchsize, generate_data(file_list[train_index], image_path, mask_path, gen_type = \"train\")), epochs=num_epoch, \n",
    "                            steps_per_epoch=(trainsize/batchsize), \n",
    "                            validation_steps=(valsize/batchsize),\n",
    "                            validation_data=batch_generator(batchsize, generate_data(file_list[val_index], image_path, mask_path, gen_type = \"val\")), \n",
    "                            validation_freq=1, \n",
    "                            verbose = 1, \n",
    "                            callbacks=[reduce_lr],\n",
    "                            )\n",
    "    val_gen  = generate_data_pred(file_list[val_index], image_path, mask_path, gen_type = \"val\")\n",
    "    for i in range(valsize):\n",
    "        time_start = time.time()\n",
    "        original_img, original_mask, X, y_true = next(val_gen)\n",
    "        original_shape = original_img.shape\n",
    "        y_pred = model.predict(np.expand_dims(X,0))\n",
    "        _,y_pred_thr = cv2.threshold(y_pred[0,:,:,0]*255, 127, 255, cv2.THRESH_BINARY)\n",
    "        y_pred = (y_pred_thr/255).astype(int)\n",
    "        dice_resized = dice_score(y_true[:,:,0],y_pred)\n",
    "        #jaccard_resized = jaccard_score(y_true[:,:,0],y_pred, average=\"macro\")\n",
    "        \n",
    "        y_pred_original = cv2.resize(y_pred.astype(float), (original_shape[1],original_shape[0]), interpolation= cv2.INTER_LINEAR)\n",
    "        dice_original = dice_score(original_mask[:,:,0],y_pred_original.astype(int)*255)\n",
    "        #jaccard_original = jaccard_score(original_mask[:,:,0],y_pred_original.astype(int)*255, average=\"macro\")\n",
    "        \n",
    "        validation_dice_original[i,cv_count] = dice_original\n",
    "        validation_dice_resized[i,cv_count] = dice_resized\n",
    "        #validation_jaccard_original[i,cv_count] = jaccard_original\n",
    "        #validation_jaccard_resized[i,cv_count] = jaccard_resized\n",
    "        \n",
    "        if i < 5:\n",
    "            plt.figure(figsize=(20,10))\n",
    "            plt.subplot(1,2,1)\n",
    "            plt.imshow(original_img, 'gray', interpolation='none')\n",
    "            plt.imshow(original_mask/255.0, 'jet', interpolation='none', alpha=0.4)\n",
    "            plt.subplot(1,2,2)\n",
    "            plt.imshow(original_img, 'gray', interpolation='none')\n",
    "            plt.imshow(y_pred_original, 'jet', interpolation='none', alpha=0.4)\n",
    "            plt.show()\n",
    "        \n",
    "    dice_resized_mean = validation_dice_resized[:,cv_count].mean()\n",
    "    dice_original_mean = validation_dice_original[:,cv_count].mean()\n",
    "    #jaccard_resized_mean = validation_jaccard_resized[:,cv_count].mean()\n",
    "    #jaccard_original_mean = validation_jaccard_original[:,cv_count].mean()\n",
    "        \n",
    "    print(\"--------------------------------------\")\n",
    "    print(\"Mean validation DICE (on resized data):\", dice_resized_mean) \n",
    "    print(\"Mean validation DICE (on original data):\", dice_original_mean)\n",
    "    print(\"--------------------------------------\")\n",
    "    #print(\"Mean validation Jaccard (on resized data):\", jaccard_resized_mean) \n",
    "    #print(\"Mean validation Jaccard (on original data):\", jaccard_original_mean)\n",
    "    #print(\"--------------------------------------\")\n",
    "    run[\"Dice Resized\"].log(dice_resized_mean)\n",
    "    run[\"Dice Original\"].log(dice_original_mean)\n",
    "    #run[\"Jaccard Resized\"].log(jaccard_resized_mean)\n",
    "    #run[\"Jaccard Original\"].log(jaccard_original_mean)\n",
    "    runtime = time.time() - time_start \n",
    "    print('Runtime: {} sec'.format(runtime))\n",
    "    run[\"Runtime\"] = runtime\n",
    "    cv_count +=1\n",
    "run.stop()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:06:12.906615Z",
     "iopub.status.busy": "2021-09-27T17:06:12.9061Z",
     "iopub.status.idle": "2021-09-27T17:06:12.916859Z",
     "shell.execute_reply": "2021-09-27T17:06:12.916255Z",
     "shell.execute_reply.started": "2021-09-27T17:06:12.906565Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_test_data(filelist, img_path):\n",
    "    while True:\n",
    "        for i in filelist:\n",
    "            X_train_orig = cv2.imread(img_path + i, cv2.IMREAD_COLOR )\n",
    "            X_train = cv2.resize(X_train_orig, (256,256), interpolation= cv2.INTER_LINEAR )\n",
    "            yield X_train, X_train_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:06:12.919129Z",
     "iopub.status.busy": "2021-09-27T17:06:12.918597Z",
     "iopub.status.idle": "2021-09-27T17:06:12.928157Z",
     "shell.execute_reply": "2021-09-27T17:06:12.927384Z",
     "shell.execute_reply.started": "2021-09-27T17:06:12.918934Z"
    }
   },
   "outputs": [],
   "source": [
    "test_file_path = \"../input/kvasir-polyp-testset/MedAI_2021_Polyp_Segmentation_Test_Dataset/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:06:12.929927Z",
     "iopub.status.busy": "2021-09-27T17:06:12.929636Z",
     "iopub.status.idle": "2021-09-27T17:06:12.97439Z",
     "shell.execute_reply": "2021-09-27T17:06:12.973756Z",
     "shell.execute_reply.started": "2021-09-27T17:06:12.929879Z"
    }
   },
   "outputs": [],
   "source": [
    "test_file_list = np.asarray(os.listdir(test_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:06:12.976378Z",
     "iopub.status.busy": "2021-09-27T17:06:12.97608Z",
     "iopub.status.idle": "2021-09-27T17:06:12.983913Z",
     "shell.execute_reply": "2021-09-27T17:06:12.983227Z",
     "shell.execute_reply.started": "2021-09-27T17:06:12.97627Z"
    }
   },
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch == 18:\n",
    "        return lr * 0.1\n",
    "    elif epoch == 20:\n",
    "        return lr * 0.1\n",
    "    else:\n",
    "        return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:06:12.987961Z",
     "iopub.status.busy": "2021-09-27T17:06:12.987712Z",
     "iopub.status.idle": "2021-09-27T17:06:12.995329Z",
     "shell.execute_reply": "2021-09-27T17:06:12.994389Z",
     "shell.execute_reply.started": "2021-09-27T17:06:12.987907Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(scheduler,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:06:12.997246Z",
     "iopub.status.busy": "2021-09-27T17:06:12.996826Z",
     "iopub.status.idle": "2021-09-27T17:20:53.830205Z",
     "shell.execute_reply": "2021-09-27T17:20:53.829347Z",
     "shell.execute_reply.started": "2021-09-27T17:06:12.997081Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b1_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n",
      "27164672/27164032 [==============================] - 0s 0us/step\n",
      "Epoch 1/30\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "34/33 [==============================] - 60s 2s/step - loss: 0.7402 - jacard_coef: 0.2598 - dice_coef: 0.8380\n",
      "Epoch 2/30\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "34/33 [==============================] - 28s 811ms/step - loss: 0.4653 - jacard_coef: 0.5347 - dice_coef: 0.9442\n",
      "Epoch 3/30\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "34/33 [==============================] - 26s 777ms/step - loss: 0.3522 - jacard_coef: 0.6478 - dice_coef: 0.9564\n",
      "Epoch 4/30\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "34/33 [==============================] - 27s 809ms/step - loss: 0.2982 - jacard_coef: 0.7018 - dice_coef: 0.9631\n",
      "Epoch 5/30\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "34/33 [==============================] - 27s 793ms/step - loss: 0.2654 - jacard_coef: 0.7346 - dice_coef: 0.9671\n",
      "Epoch 6/30\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "34/33 [==============================] - 27s 787ms/step - loss: 0.2624 - jacard_coef: 0.7376 - dice_coef: 0.9662\n",
      "Epoch 7/30\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "34/33 [==============================] - 26s 779ms/step - loss: 0.2594 - jacard_coef: 0.7406 - dice_coef: 0.9668\n",
      "Epoch 8/30\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "34/33 [==============================] - 28s 827ms/step - loss: 0.2423 - jacard_coef: 0.7577 - dice_coef: 0.9694\n",
      "Epoch 9/30\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "34/33 [==============================] - 27s 803ms/step - loss: 0.2531 - jacard_coef: 0.7469 - dice_coef: 0.9671\n",
      "Epoch 10/30\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "34/33 [==============================] - 28s 811ms/step - loss: 0.2284 - jacard_coef: 0.7716 - dice_coef: 0.9710\n",
      "Epoch 11/30\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "34/33 [==============================] - 27s 791ms/step - loss: 0.2340 - jacard_coef: 0.7660 - dice_coef: 0.9700\n",
      "Epoch 12/30\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "34/33 [==============================] - 28s 830ms/step - loss: 0.2377 - jacard_coef: 0.7623 - dice_coef: 0.9693\n",
      "Epoch 13/30\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "34/33 [==============================] - 28s 822ms/step - loss: 0.2206 - jacard_coef: 0.7794 - dice_coef: 0.9719\n",
      "Epoch 14/30\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "34/33 [==============================] - 28s 828ms/step - loss: 0.2147 - jacard_coef: 0.7853 - dice_coef: 0.9726\n",
      "Epoch 15/30\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "34/33 [==============================] - 27s 792ms/step - loss: 0.2259 - jacard_coef: 0.7741 - dice_coef: 0.9707\n",
      "Epoch 16/30\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "34/33 [==============================] - 27s 781ms/step - loss: 0.2039 - jacard_coef: 0.7961 - dice_coef: 0.9744\n",
      "Epoch 17/30\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "34/33 [==============================] - 26s 754ms/step - loss: 0.2077 - jacard_coef: 0.7923 - dice_coef: 0.9737\n",
      "Epoch 18/30\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "34/33 [==============================] - 26s 766ms/step - loss: 0.2116 - jacard_coef: 0.7884 - dice_coef: 0.9724\n",
      "Epoch 19/30\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.00010000000474974513.\n",
      "34/33 [==============================] - 27s 796ms/step - loss: 0.1963 - jacard_coef: 0.8037 - dice_coef: 0.9755\n",
      "Epoch 20/30\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.00010000000474974513.\n",
      "34/33 [==============================] - 28s 821ms/step - loss: 0.1898 - jacard_coef: 0.8102 - dice_coef: 0.9762\n",
      "Epoch 21/30\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 1.0000000474974514e-05.\n",
      "34/33 [==============================] - 27s 793ms/step - loss: 0.1845 - jacard_coef: 0.8155 - dice_coef: 0.9771\n",
      "Epoch 22/30\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 1.0000000656873453e-05.\n",
      "34/33 [==============================] - 27s 794ms/step - loss: 0.1941 - jacard_coef: 0.8059 - dice_coef: 0.9759\n",
      "Epoch 23/30\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 1.0000000656873453e-05.\n",
      "34/33 [==============================] - 28s 812ms/step - loss: 0.1869 - jacard_coef: 0.8131 - dice_coef: 0.9765\n",
      "Epoch 24/30\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 1.0000000656873453e-05.\n",
      "34/33 [==============================] - 26s 779ms/step - loss: 0.1788 - jacard_coef: 0.8212 - dice_coef: 0.9776\n",
      "Epoch 25/30\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 1.0000000656873453e-05.\n",
      "34/33 [==============================] - 28s 815ms/step - loss: 0.1841 - jacard_coef: 0.8159 - dice_coef: 0.9770\n",
      "Epoch 26/30\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 1.0000000656873453e-05.\n",
      "34/33 [==============================] - 28s 833ms/step - loss: 0.1857 - jacard_coef: 0.8143 - dice_coef: 0.9768\n",
      "Epoch 27/30\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 1.0000000656873453e-05.\n",
      "34/33 [==============================] - 27s 783ms/step - loss: 0.1765 - jacard_coef: 0.8235 - dice_coef: 0.9781\n",
      "Epoch 28/30\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 1.0000000656873453e-05.\n",
      "34/33 [==============================] - 27s 786ms/step - loss: 0.1852 - jacard_coef: 0.8148 - dice_coef: 0.9770\n",
      "Epoch 29/30\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 1.0000000656873453e-05.\n",
      "34/33 [==============================] - 28s 823ms/step - loss: 0.1798 - jacard_coef: 0.8202 - dice_coef: 0.9776\n",
      "Epoch 30/30\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 1.0000000656873453e-05.\n",
      "34/33 [==============================] - 27s 789ms/step - loss: 0.1810 - jacard_coef: 0.8190 - dice_coef: 0.9774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f8ba9c48be0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list = np.asarray(os.listdir(\"../input/hyperkvasiraugustversion/Kvasir-SEG/images\"))\n",
    "image_path = \"../input/hyperkvasiraugustversion/Kvasir-SEG/images/\" \n",
    "mask_path = \"../input/hyperkvasiraugustversion/Kvasir-SEG/masks/\"\n",
    "batchsize = 30\n",
    "data_size = len(file_list)\n",
    "num_epoch = 30\n",
    "my_model = \"efficientnetb1\"\n",
    "img_size = (256, 256)\n",
    "num_classes = 3\n",
    "#model = get_model(img_size, num_classes)\n",
    "model = sm.Unet(my_model, encoder_weights='imagenet', input_shape=( 256,256, 3), classes=3, activation='sigmoid')\n",
    "model.compile(optimizer='Adam', loss=jacard_coef_loss, metrics = [jacard_coef, dice_coef])\n",
    "model.fit(x=batch_generator(batchsize, generate_data(file_list, image_path, mask_path, gen_type = \"train\")), epochs=num_epoch, \n",
    "                        steps_per_epoch=(len(file_list)/batchsize), \n",
    "                        verbose = 1, \n",
    "                        callbacks = [lr_schedule]\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:20:53.83237Z",
     "iopub.status.busy": "2021-09-27T17:20:53.831749Z",
     "iopub.status.idle": "2021-09-27T17:20:53.836894Z",
     "shell.execute_reply": "2021-09-27T17:20:53.836207Z",
     "shell.execute_reply.started": "2021-09-27T17:20:53.832313Z"
    }
   },
   "outputs": [],
   "source": [
    "test_gen  = generate_test_data(test_file_list,test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:20:53.838952Z",
     "iopub.status.busy": "2021-09-27T17:20:53.838274Z",
     "iopub.status.idle": "2021-09-27T17:36:45.761249Z",
     "shell.execute_reply": "2021-09-27T17:36:45.757787Z",
     "shell.execute_reply.started": "2021-09-27T17:20:53.838905Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(test_file_list)):\n",
    "        test_img, original_img= next(test_gen)\n",
    "        original_shape = original_img.shape\n",
    "        y_pred = model.predict(np.expand_dims(test_img,0))\n",
    "        _,y_pred_thr = cv2.threshold(y_pred[0,:,:,0]*255, 127, 255, cv2.THRESH_BINARY)\n",
    "        y_pred = (y_pred_thr/255).astype(int)\n",
    "        y_pred_original = cv2.resize(y_pred.astype(float), (original_shape[1],original_shape[0]), interpolation= cv2.INTER_LINEAR)\n",
    "        #cv2.imwrite(\"./\" + test_file_list[i], y_pred_original)\n",
    "        imageio.imwrite(\"./\" + test_file_list[i], y_pred_original)\n",
    "        #plt.imshow(y_pred_original)\n",
    "        #plt.axis('off')\n",
    "        #plt.savefig(\"./\" + test_file_list[i],bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
